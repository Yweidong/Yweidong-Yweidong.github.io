{"pages":[{"title":"","text":"个人简介 分享很喜欢的老罗的一段话： “每一个生命来到世间都注定改变世界，别无选择。要么变得好一点，要么变得坏一点。你如果走进社会为了生存为了什么不要脸的理由，变成了一个恶心的成年人社会中的一员，那你就把这个世界变得恶心了一点点。如果你一生刚正不阿，如果你一生耿直，没有做任何恶心的事情，没做对别人有害的事情，一辈子拼了老命勉强把自己身边的几个人照顾好了，没有成名没有发财，没有成就伟大的事业，然后耿着脖子一生正直，到了七八十岁耿着脖子去世了。你这一生是不是没有改变世界？你还是改变世界了，你把这个世界变得美好了一点点。因为世界上又多了一个好人。“ 善恶终有报,天道好轮回。不信抬头看,苍天饶过谁。无论何时何地，我们都要保持一颗积极乐观、善良感恩的心。但行好事莫问前程，永远年轻，永远热内盈眶，永远保持正能量。💪💪💪💪💪💪冲鸭！！！！ -&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;个人信息：计算机科学与技术专业从事JAVA后端开发码畜一枚坚信代码改变世界 博客信息 网站采用的Icarus主题 追求尽可能的简洁，清晰，易用。 在Icarus主题之上进行了部分修改。 更新日志：–2020.09.20：icarus4.0适配–2020.01.18：icarus3.0适配–2019.11.17：增加深色主题开关–2019.10.30：去图，精简卡片–2019.10.22：改版部分显示，优化速度–2019.10.16：文章列表加上评论数显示–2019.10.13：改版评论–2019.09.25：图片、资源接入CDN免费jsDelivr、文章加入置顶–2019.09.19：开源博客代码–2019.09.19：修改布局，拉伸布局，更宽的展示–2019.09.18：修改友链ui为一行三个，并适配移动端，暗黑模式文章增加评论链接，增加留言链接–2019.09.14：增加精简next主题–2019.09.14：利用中秋节放假，重做了首页的热门推荐、加个widget最新评论框、归档页加入文章贡献概览面板 本站推荐索引 博客主题相关 github Issue 作为博客微型数据库的应用 github page网站cdn优化加速 博客源码分享 博客换肤的一种实现方式思路 博客中gitalk最新评论的获取 博客图片上传picgo工具github图传使用 安装、部分配置icarus主题中文版 技术知识点 Java并发知识点 法律法规 法律法规数据库 中华人民共和国国旗法 中华人民共和国宪法 中华人民共和国消费者权益保护法 中华人民共和国刑事诉讼法 中华人民共和国婚姻法 中华人名共和国网络安全法 中华人民共和国劳动法 其他 网易云音乐歌单分享 计划2020计划 2019.12.31 2020-GOALS 跑两三场马拉松 2019计划 2018.12.31/21:59:00-&gt;更新于2019.12.31 2019-GOALS 购买的专业书籍至少看完一遍（并发、重构、设计模式…）-&gt; 95% 额外： 追了很多剧 总结： 有优点有缺点，没坚持下来的还是太多，追了太多剧。以后多学习，多思考！ 时间轴记录","link":"/about/index.html"},{"title":"","text":"🎈🎈微笑墙🎈🎈 彭小苒 唐艺昕 李一桐 gakki 图片搜集于互联网，侵权请留言，马上处理😊。","link":"/album/index.html"},{"title":"","text":"&nbsp;&nbsp;听听音乐 音乐播放器由mePlayer提供，布局参照网友博客所作，感谢作者的辛勤付出。更多音乐分享请查看歌单。 &nbsp;&nbsp;看看视频 ->点击以下条目开始播放视频,向下滑动查看更多","link":"/media/index.html"},{"title":"","text":"来而不往非礼也畅所欲言，有留必应","link":"/message/index.html"},{"title":"","text":"申请友链须知 原则上只和技术类博客交换，但不包括含有和色情、暴力、政治敏感的网站。 不和剽窃、侵权、无诚信的网站交换，优先和具有原创作品的网站交换。 申请请提供：站点名称、站点链接、站点描述、logo或头像（不要设置防盗链）。 排名不分先后，刷新后重排，更新信息后请留言告知。 会定期清理很久很久不更新的、不符合要求的友链，不再另行通知。 本站不存储友链图片，如果友链图片换了无法更新。图片裂了的会替换成默认图，需要更换的请留言告知。 本站友链信息如下，申请友链前请先添加本站信息： 网站图标：https://removeif.github.io/images/avatar.jpg 网站名称：辣椒の酱 网站地址：https://removeif.github.io 网站简介：后端开发，技术分享 加载中，稍等几秒...","link":"/friend/index.html"},{"title":"音乐歌单收藏","text":"温馨提示：选择喜欢的音乐双击播放，由于版权原因部分不能播放。如果喜欢歌单收藏一下，去网易云都能播放哟！","link":"/music/index.html"},{"title":"","text":"碎碎念 tips：github登录后按时间正序查看、可点赞加❤️、本插件地址..「+99次查看」 碎碎念加载中，请稍等... $.getScript(\"/js/gitalk_self.min.js\", function () { var gitalk = new Gitalk({ clientID: '46a9f3481b46ea0129d8', clientSecret: '79c7c9cb847e141757d7864453bcbf89f0655b24', id: '666666', repo: 'issue_database', owner: 'removeif', admin: \"removeif\", createIssueManually: true, distractionFreeMode: false }); gitalk.render('comment-container1'); });","link":"/self-talking/index.html"}],"posts":[{"title":"Netty的整体架构脉络","text":"Netty 整体结构 Netty 是一个设计非常用心的网络基础组件，Netty 官网给出了有关 Netty 的整体功能模块结构，却没有其他更多的解释。从图中，我们可以清晰地看出 Netty 结构一共分为三个模块：(以下为官网图片) Core核心层 Core 核心层是 Netty 最精华的内容，它提供了底层网络通信的通用抽象和实现，包括可扩展的事件模型、通用的通信 API、支持零拷贝的 ByteBuf 等。 Protocol Support协议支持层 协议支持层基本上覆盖了主流协议的编解码实现，如 HTTP、SSL、Protobuf、压缩、大文件传输、WebSocket、文本、二进制等主流协议，此外 Netty 还支持自定义应用层协议。Netty 丰富的协议支持降低了用户的开发成本，基于 Netty 我们可以快速开发 HTTP、WebSocket 等服务。 TransportService 传输服务层 传输服务层提供了网络传输能力的定义和实现方法。它支持 Socket、HTTP 隧道、虚拟机管道等传输方式。Netty 对 TCP、UDP 等数据传输做了抽象和封装，用户可以更聚焦在业务逻辑实现上，而不必关系底层数据传输的细节。 Netty逻辑架构 下图是 Netty 的逻辑处理架构。Netty 的逻辑处理架构为典型网络分层架构设计，共分为网络通信层、事件调度层、服务编排层，每一层各司其职。图中包含了 Netty 每一层所用到的核心组件。我将为你介绍 Netty 的每个逻辑分层中的各个核心组件以及组件之间是如何协调运作的。 网络通信层 网络通信层的职责是执行网络 I/O 的操作。它支持多种网络协议和 I/O 模型的连接操作。当网络数据读取到内核缓冲区后，会触发各种网络事件，这些网络事件会分发给事件调度层进行处理。 BootStrap &amp;&amp; ServerBootStrap Bootstrap 是“引导”的意思，它主要负责整个 Netty 程序的启动、初始化、服务器连接等过程，它相当于一条主线，串联了 Netty 的其他核心组件。 如下图所示，Netty 中的引导器共分为两种类型：一个为用于客户端引导的 Bootstrap，另一个为用于服务端引导的 ServerBootStrap，它们都继承自抽象类 AbstractBootstrap。 Bootstrap 和 ServerBootStrap 十分相似，两者非常重要的区别在于 Bootstrap 可用于连接远端服务器，只绑定一个 EventLoopGroup。而 ServerBootStrap 则用于服务端启动绑定本地端口，会绑定两个 EventLoopGroup，这两个 EventLoopGroup 通常称为 Boss 和 Worker。 ServerBootStrap 中的 Boss 和 Worker 是什么角色呢？它们之间又是什么关系？这里的 Boss 和 Worker 可以理解为“老板”和“员工”的关系。每个服务器中都会有一个 Boss，也会有一群做事情的 Worker。Boss 会不停地接收新的连接，然后将连接分配给一个个 Worker 处理连接。 有了 Bootstrap 组件，我们可以更加方便地配置和启动 Netty 应用程序，它是整个 Netty 的入口，串接了 Netty 所有核心组件的初始化工作。 Channel Channel 的字面意思是“通道”，它是网络通信的载体。Channel提供了基本的 API 用于网络 I/O 操作，如 register、bind、connect、read、write、flush 等。Netty 自己实现的 Channel 是以 JDK NIO Channel 为基础的，相比较于 JDK NIO，Netty 的 Channel 提供了更高层次的抽象，同时屏蔽了底层 Socket 的复杂性，赋予了 Channel 更加强大的功能，你在使用 Netty 时基本不需要再与 Java Socket 类直接打交道。 下图是 Channel 家族的图谱。AbstractChannel 是整个家族的基类，派生出 AbstractNioChannel、AbstractOioChannel、AbstractEpollChannel 等子类，每一种都代表了不同的 I/O 模型和协议类型。常用的 Channel 实现类有： NioServerSocketChannel/EpollServerSocketChannel 都是异步TCP服务端； NioSocketChannel/EpollSocketChannel 都是异步TCP客户端 两者的区别是一个使用了select模型，一个使用了epoll 模型(这里不深入展开) 当然 Channel 会有多种状态，如连接建立、连接注册、数据读写、连接销毁等。随着状态的变化，Channel 处于不同的生命周期，每一种状态都会绑定相应的事件回调，下面的表格我列举了 Channel 最常见的状态所对应的事件回调。 事件 说明 channelRegistered Channel创建后被注册到EventLoop上 channelUnregistered Channel创建后未注册或者从EventLoop上取消 channelActive Channel处于就绪状态，可以被读写 channelInactive Channel 处于非就绪状态 channelRead Channel可以从远端读取到数据 channelReadComplete Channel读取数据完成 BootStrap 和 ServerBootStrap 分别负责客户端和服务端的启动，它们是非常强大的辅助工具类；Channel 是网络通信的载体，提供了与底层 Socket 交互的能力。那么 Channel 生命周期内的事件都是如何被处理的呢？那就是 Netty 事件调度层的工作职责了。 事件调度层 事件调度层的职责是通过 Reactor 线程模型对各类事件进行聚合处理，通过 Selector 主循环线程集成多种事件（ I/O 事件、信号事件、定时事件等），实际的业务处理逻辑是交由服务编排层中相关的 Handler 完成。 事件调度层的核心组件包括 EventLoopGroup、EventLoop。 EventLoopGroup &amp;&amp; EventLoop。 EventLoopGroup 本质是一个线程池，主要负责接收 I/O 请求，并分配线程执行处理请求。在下图中，我为你讲述了 EventLoopGroup、EventLoop 与 Channel 的关系。 一个 EventLoopGroup 往往包含一个或者多个 EventLoop。EventLoop 用于处理 Channel 生命周期内的所有 I/O 事件，如 accept、connect、read、write 等 I/O 事件。 EventLoop 同一时间会与一个线程绑定，每个 EventLoop 负责处理多个 Channel。 每新建一个 Channel，EventLoopGroup 会选择一个 EventLoop 与其绑定。该 Channel 在生命周期内都可以对 EventLoop 进行多次绑定和解绑。 下图是 EventLoopGroup 的家族图谱。可以看出 Netty 提供了 EventLoopGroup 的多种实现，而且 EventLoop 则是 EventLoopGroup 的子接口，所以也可以把 EventLoop 理解为 EventLoopGroup，但是它只包含一个 EventLoop 。 1234567891011/** * Will handle all the I/O operations for a {@link Channel} once registered. * * One {@link EventLoop} instance will usually handle more than one {@link Channel} but this may depend on * implementation details and internals. * */public interface EventLoop extends OrderedEventExecutor, EventLoopGroup { @Override EventLoopGroup parent();} EventLoopGroup 的实现类是 NioEventLoopGroup，NioEventLoopGroup 也是 Netty 中最被推荐使用的线程模型。NioEventLoopGroup 继承于 MultithreadEventLoopGroup，是基于 NIO 模型开发的，可以把 NioEventLoopGroup 理解为一个线程池，每个线程负责处理多个 Channel，而同一个 Channel 只会对应一个线程。 EventLoopGroup 是 Netty 的核心处理引擎，那么 EventLoopGroup 和之前提到的 Reactor 线程模型到底是什么关系呢？其实 EventLoopGroup 是 Netty Reactor 线程模型的具体实现方式，Netty 通过创建不同的 EventLoopGroup 参数配置，就可以支持 Reactor 的三种线程模型： 单线程模型：EventLoopGroup 只包含一个 EventLoop，Boss 和 Worker 使用同一个EventLoopGroup； 多线程模型：EventLoopGroup 包含多个 EventLoop，Boss 和 Worker 使用同一个EventLoopGroup； 主从多线程模型：EventLoopGroup 包含多个 EventLoop，Boss 是主 Reactor，Worker 是从 Reactor，它们分别使用不同的 EventLoopGroup，主 Reactor 负责新的网络连接 Channel 创建，然后把 Channel 注册到从 Reactor。 在介绍完事件调度层之后，可以说 Netty 的发动机已经转起来了，事件调度层负责监听网络连接和读写操作，然后触发各种类型的网络事件，需要一种机制管理这些错综复杂的事件，并有序地执行，接下来我们便一起学习 Netty 服务编排层中核心组件的职责。 服务编排层 服务编排层的职责是负责组装各类服务，它是 Netty 的核心处理链，用以实现网络事件的动态编排和有序传播。 服务编排层的核心组件包括 ChannelPipeline、ChannelHandler、ChannelHandlerContext。 ChannelPipeline ChannelPipeline 是 Netty 的核心编排组件，负责组装各种 ChannelHandler，实际数据的编解码以及加工处理操作都是由 ChannelHandler 完成的。ChannelPipeline 可以理解为ChannelHandler 的实例列表——内部通过双向链表将不同的 ChannelHandler 链接在一起。当 I/O 读写事件触发时，ChannelPipeline 会依次调用 ChannelHandler 列表对 Channel 的数据进行拦截和处理。 ChannelPipeline 是线程安全的，因为每一个新的 Channel 都会对应绑定一个新的 ChannelPipeline。一个 ChannelPipeline 关联一个 EventLoop，一个 EventLoop 仅会绑定一个线程。 C hannelPipeline大致结构流程 12345678910111213141516171819202122232425262728293031323334353637383940* &lt;pre&gt;* I/O Request* via {@link Channel} or* {@link ChannelHandlerContext}* |* +---------------------------------------------------+---------------+* | ChannelPipeline | |* | \\|/ |* | +---------------------+ +-----------+----------+ |* | | Inbound Handler N | | Outbound Handler 1 | |* | +----------+----------+ +-----------+----------+ |* | /|\\ | |* | | \\|/ |* | +----------+----------+ +-----------+----------+ |* | | Inbound Handler N-1 | | Outbound Handler 2 | |* | +----------+----------+ +-----------+----------+ |* | /|\\ . |* | . . |* | ChannelHandlerContext.fireIN_EVT() ChannelHandlerContext.OUT_EVT()|* | [ method call] [method call] |* | . . |* | . \\|/ |* | +----------+----------+ +-----------+----------+ |* | | Inbound Handler 2 | | Outbound Handler M-1 | |* | +----------+----------+ +-----------+----------+ |* | /|\\ | |* | | \\|/ |* | +----------+----------+ +-----------+----------+ |* | | Inbound Handler 1 | | Outbound Handler M | |* | +----------+----------+ +-----------+----------+ |* | /|\\ | |* +---------------+-----------------------------------+---------------+* | \\|/* +---------------+-----------------------------------+---------------+* | | | |* | [ Socket.read() ] [ Socket.write() ] |* | |* | Netty Internal I/O Threads (Transport Implementation) |* +-------------------------------------------------------------------+* &lt;/pre&gt; 从上图可以看出，ChannelPipeline 中包含入站 ChannelInboundHandler 和出站 ChannelOutboundHandler 两种处理器，我们结合客户端和服务端的数据收发流程来理解 Netty 的这两个概念。 客户端和服务端都有各自的 ChannelPipeline。以客户端为例，数据从客户端发向服务端，该过程称为出站，反之则称为入站。数据入站会由一系列 InBoundHandler 处理，然后再以相反方向的 OutBoundHandler 处理后完成出站。我们经常使用的编码 Encoder 是出站操作，解码 Decoder 是入站操作。服务端接收到客户端数据后，需要先经过 Decoder 入站处理后，再通过 Encoder 出站通知客户端。所以客户端和服务端一次完整的请求应答过程可以分为三个步骤：客户端出站（请求数据）、服务端入站（解析数据并执行业务逻辑）、服务端出站（响应结果）。 ChannelHandler &amp;&amp; ChannelHandlerContext 下图描述了 Channel 与 ChannelPipeline 的关系，从图中可以看出，每创建一个 Channel 都会绑定一个新的 ChannelPipeline，ChannelPipeline 中每加入一个 ChannelHandler 都会绑定一个 ChannelHandlerContext。由此可见，ChannelPipeline、ChannelHandlerContext、ChannelHandler 三个组件的关系是密切相关的 ChannelHandlerContext 用于保存 ChannelHandler 上下文，通过 ChannelHandlerContext 我们可以知道 ChannelPipeline 和 ChannelHandler 的关联关系。ChannelHandlerContext 可以实现 ChannelHandler 之间的交互，ChannelHandlerContext 包含了 ChannelHandler 生命周期的所有事件，如 connect、bind、read、flush、write、close 等。此外，你可以试想这样一个场景，如果每个 ChannelHandler 都有一些通用的逻辑需要实现，没有 ChannelHandlerContext 这层模型抽象，你是不是需要写很多相同的代码呢？ 1234567public interface ChannelHandlerContext extends AttributeMap, ChannelInboundInvoker, ChannelOutboundInvoker { /** * Return the {@link Channel} which is bound to the {@link ChannelHandlerContext}. */ Channel channel(); ... 以上便是 Netty 的逻辑处理架构，可以看出 Netty 的架构分层设计得非常合理，屏蔽了底层 NIO 以及框架层的实现细节，对于业务开发者来说，只需要关注业务逻辑的编排和实现即可。 组件关系梳理 服务端启动初始化时有 Boss EventLoopGroup 和 Worker EventLoopGroup 两个组件，其中 Boss 负责监听网络连接事件。当有新的网络连接事件到达时，则将 Channel 注册到 Worker EventLoopGroup。 Worker EventLoopGroup 会分配一个 EventLoop 负责处理该 Channel 的读写事件。每个 EventLoop 都是单线程的，通过 Selector 进行事件循环。 当客户端发起 I/O 读写事件时，服务端 EventLoop 会进行数据的读取，然后通过 Pipeline 触发各种监听器进行数据的加工处理。 客户端数据会被传递到 ChannelPipeline 的第一个 ChannelInboundHandler 中，数据处理完成后，将加工完成的数据传递给下一个 ChannelInboundHandler。 当数据写回客户端时，会将处理结果在 ChannelPipeline 的 ChannelOutboundHandler 中传播，最后到达客户端。 Netty 源码结构 Netty 源码分为多个模块，模块之间职责划分非常清楚。如同上文整体功能模块一样，Netty 源码模块的划分也是基本契合的。 我们不仅可以使用 Netty all-in-one 的 Jar 包，也可以单独使用其中某些工具包。下面我根据 Netty 的分层结构以及实际的业务场景具体介绍 Netty 中常用的工具包。 Core核心层模块 netty-common模块是 Netty 的核心基础包，提供了丰富的工具类，其他模块都需要依赖它。在 common 模块中，常用的包括通用工具类和自定义并发包 通用工具类：比如定时器工具 TimerTask、时间轮 HashedWheelTimer 等。 自定义并发包：比如异步模型Future &amp; Promise、相比 JDK 增强的 FastThreadLocal 等。 在netty-buffer 模块中Netty自己实现了的一个更加完备的ByteBuf 工具类，用于网络通信中的数据载体。由于人性化的 Buffer API 设计，它已经成为 Java ByteBuffer 的完美替代品。ByteBuf 的动态性设计不仅解决了 ByteBuffer 长度固定造成的内存浪费问题，而且更安全地更改了 Buffer 的容量。此外 Netty 针对 ByteBuf 做了很多优化，例如缓存池化、减少数据拷贝的 CompositeByteBuf 等。 netty-resover模块主要提供了一些有关基础设施的解析工具，包括IP Address，HostName,DNS等。 Protocol Support 协议支持层膜哦快 netty-codec模块主要负责编解码工作，通过编解码实现原始字节数据业务实体对象之间的相互转化。如下图所示，Netty 支持了大多数业界主流协议的编解码器，如 HTTP、HTTP2、Redis、XML 等，为开发者节省了大量的精力。此外该模块提供了抽象的编解码类 ByteToMessageDecoder 和 MessageToByteEncoder，通过继承这两个类我们可以轻松实现自定义的编解码逻辑。 netty-handler模块主要负责数据处理工作。Netty 中关于数据处理的部分，本质上是一串有序 handler 的集合。netty-handler 模块提供了开箱即用的 ChannelHandler 实现类，例如日志、IP 过滤、流量整形等，如果你需要这些功能，仅需在 pipeline 中加入相应的 ChannelHandler 即可。 Transport Service 传输服务层模块 netty-transport 模块可以说是 Netty 提供数据处理和传输的核心模块。该模块提供了很多非常重要的接口，如 Bootstrap、Channel、ChannelHandler、EventLoop、EventLoopGroup、ChannelPipeline 等。其中 Bootstrap 负责客户端或服务端的启动工作，包括创建、初始化 Channel 等；EventLoop 负责向注册的 Channel 发起 I/O 读写操作；ChannelPipeline 负责 ChannelHandler 的有序编排，这些组件在介绍 Netty 逻辑架构的时候都有所涉及。","link":"/netty/Netty%E7%9A%84%E6%95%B4%E4%BD%93%E6%9E%B6%E6%9E%84%E8%84%89%E7%BB%9C.html"},{"title":"JVM 卷","text":"JVM 内存区域 这张图就是一个 JVM 运行时数据图，「紫色区域代表是线程共享的区域」，JAVA 程序在运行的过程中会把他管理的内存划分为若干个不同的数据区域，「每一块的数据区域所负责的功能都是不同的，他们也有不同的创建时间和销毁时间」 程序计数器： 是「程序控制流的指示器，循环，跳转，异常处理，线程的恢复等工作都需要依赖程序计数器去完成」。程序计数器是「线程私有」的，它的「生命周期是和线程保持一致」的，我们知道，N 个核心数的 CPU 在同一时刻，最多有 N个线程同时运行，在我们真实的使用过程中可能会创建很多线程，JVM 的多线程其实是通过线程轮流切换，分配处理器执行时间来实现的。既然涉及的线程切换，所以每条线程必须有一个独立的程序计数器; 虚拟机栈：其描述的就是线程内存模型，「也可以称作线程栈」，也是每个「线程私有」的，「生命周期与线程保持一致」。在每个方法执行的时候，jvm 都会同步创建一个栈帧去存储局部变量表，操作数栈，动态连接，方法出口等信息。一个方法的生命周期就贯彻了一个栈帧从入栈到出栈的全部过程; 本地方法栈：java底层用了很多c的代码去实现，而其调用c端的方法上都会有native，代表本地方法服务，而本地方法栈就是为其服务的； 堆：堆可以说是jvm中最大的一块儿内存区域了，它是所有线程共享的，不管你是初学者还是资深开发，多少都会听说过堆，毕竟几乎所有的对象都会在堆中分配； 方法区：也是所有「线程共享」的区域，它「存储」了被 jvm 加载的类型信息、常量、静态变量等数据。运行时常量池就是方法区的一部分，编译期生成的各种字面量与符号引用就存储在其中; 直接内存:这部分数据并「不是 jvm 运行时数据区的一部分」，nio 就会使用到直接内存，也可以说「堆外内存」，通常会「配合虚引用一起去使用」，就是为了资源释放，会将堆外内存开辟空间的信息存储到一个队列中，然后GC会去清理这部分空间。堆外内存优势在 IO 操作上，对于网络 IO，使用 Socket 发送数据时，能够节省堆内存到堆外内存的数据拷贝，所以性能更高。Netty 使用堆外内存池来实现零拷贝技术。对于磁盘 IO 时，也可以使用内存映射，来提升性能。另外，更重要的几乎不用考虑堆内存烦人的 GC 问题。但是既然是内存。也会受到本机总内存的限制 首先通过编译器把 Java源代码转换成字节码，Class loader(类装载)再把字节码加载到内存中，将其放在运行时数据区的方法区内，而字节码文件只是 JVM 的一套指令集规范，并不能直接交给底层操作系统去执行，因此需要特定的命令解析器执行引擎（Execution Engine），将字节码翻译成底层系统指令，再交由 CPU 去执行，而这个过程中需要调用其他语言的本地库接口（Native Interface）来实现整个程序的功能。 垃圾对象是怎么找到的？引用计数法就是给对象添加一个计数器 每当有一个地方引用它的时候，计数器就加1 每当有一个引用失效的时候，计数器就减1 当计数器的值为0的时候，那么该对象就是垃圾了。这种方案的原理很简单，而且判定的效率也非常高，但是却可能会有其他的额外情况需要考虑 比如两个对象循环引用，a 对象引用了 b 对象，b 对象也引用了 a 对象，a、b 对象却没有再被其他对象所引用了，其实正常来说这两个对象已经是垃圾了，因为没有其他对象在使用了，但是计数器内的数值却不是 0，所以引用计数算法就无法回收它们。这种算法是比较直接的找到垃圾，然后去回收，也被称为”直接垃圾收集”。 根可达算法这也是JVM 默认使用的寻找垃圾算法它的原理就是定义了一系列的根，我们把它称为 GC Roots ，从 GC Roots 开始往下进行搜索，走过的路径我们把它称为 引用链 ，当一个对象到 GC Roots 之间没有任何引用链相连时，那么这个对象就可以被当做垃圾回收了。 如图，根可达算法就可以避免计数器算法不好解决的循环引用问题，Object 6、Object 7、Object 8彼此之前有引用关系，但是没有与GC Roots 相连，那么就会被当做垃圾所回收。 GC Roots 有哪些在java中，有固定的GC Roots对象和不固定的临时GC Roots对象 固定的GC Roots对象 在虚拟机栈(栈帧的本地变量表)中所引用的对象，譬如各个线程被调用的方法堆栈中使用到的参数、局部变量、临时变量等; 在方法区中类静态属性引用的对象，譬如 Java 类的引用静态变量; 在方法区中常量引用的对象，譬如字符串常量池中的引用; 在方法区栈中 JNI (譬如 Native 方法)引用的对象 Java 虚拟机内部的引用，如基本数据类型对应的 Class 对象，一些常驻的异常对象(空指针异常、OOM等)，还有类加载器 所有被 Synchronized 持有的对象 反应 Java 虚拟机内部情况的 JMXBean、JVMTI 中注册的回调本地代码缓存等 不固定的临时GC Roots对象 目前的垃圾回收大部分都是分代收集和局部回收，如果只针对某一部分区域进行局部回收，那么就必须要考虑的当前区域的对象有可能正被其他区域的对象所引用，这时候就要将这部分关联的对象也添加到 GC Roots 中去来确保根可达算法的准确性。这种算法是利用了逆向思维，找到使用的对象，剩下的就是垃圾，也被称为”间接垃圾收集”。 Java 有哪四种引用类型强引用 Object o = new Object 就是一种强引用的关系，无论任何情况下，只要强引用关系还存在，垃圾回收器就不会回收掉被引用的对象 软引用 当内存空间不足时，就会回收软引用对象； 软引用用来描述那些有用但是没必要的对象。 1SoftReference sr = new SoftReference(str); 弱引用 弱引用要比软引用更弱一些，它 只能够存活到下次垃圾回收之前。也就是说，垃圾回收器开始工作，回收掉所有只被弱引用关联的对象. 在ThreadLocal中就使用了弱引用来防止内存泄漏。 1WeekReference wr = new WeekReference(str); 虚引用 虚引用是最弱的一种引用关系，它的唯一作用是用来作为一种通知。如零拷贝(Zero Copy)，开辟了堆外内存，虚引用在这里使用，会将这部分信息存储到一个队列中，以便于后续对堆外内存的回收管理. 分代收集理论大多数的垃圾回收器都遵循了分代收集的理论进行设计，它建立在两个分代假说之上: 弱分代假说：绝大多数对象都是朝生夕灭的； 强分代假说：熬过越多次垃圾回收过程的对象就越难消亡； 这两种假说的设计原则都是相同的:垃圾收集器应该将jvm划分出不同的区域，把那些较难回收的对象放在一起（一般指老年代），这个区域的垃圾回收频率就可以降低，减少垃圾回收的开销。剩下的区域(一般指新生代)可以用较高的频率去回收，并且只需要去关心那些存活的对象，也不用标记出需要回收的垃圾，这样就能够以较低的代价去完成垃圾回收. 跨代引用假说：如果某个新生代的对象存在了跨代引用，但是老年代的对象是很难消亡的，那么随着时间的推移，这个新生代对象也会慢慢晋升为老年代对象，那么这种跨代引用也就被消除了 由于跨代引用是很少的，所以我们不应该为了少量的跨代引用去扫描整个老年代的数据，只需要在新生代对象建立一个记忆集来记录引用信息。记忆集:将老年代分为若干个小块，每块区域中有 N 个对象，在对象引用信息发生变动的时候来维护记忆集数据的准确性，这样每次发生了 “Minor GC” 的时候只需要将记忆集中的对象添加到 **”GC Roots”**中就可以了 垃圾收集算法有哪些标记清除算法这种算法的实现是很简单的，有两种方式 标记出垃圾，然后清理掉； 标记出存活的对象，回收其他的空间。 这种算法有两个缺点： 随着对象越来越多，那么所需要消耗的时间就会越来越多； 标记清除后会导致碎片化，如果有大对象分配很有可能分配不下而出发另一次的垃圾收集动作 标记复制算法 这种算法解决了第一种算法碎片化的问题。就是开辟两块完全相同的区域，对象只在其中一篇区域内分配，然后标记出那些存活的对象，按顺序整体移到另外一个空间，如下图，可以看到回收后的对象是排列有序的，这种操作只需要移动指针就可以完成，效率很高，之后就回收移除前的空间。 这种算法的缺点也是很明显的 浪费过多的内存，使现有的可用空间变为原先的一半; 标记整理算法这种算法可以说是结合了前两种算法，既有标记删除，又有整理功能。 这种算法就是通过标记清除算法找到存活的对象，然后将所有存活的对象，向空间的一端移动，然后回收掉其他的内存。 什么是STW Java 中Stop-The-World机制简称 STW ，是在执行垃圾收集算法时，Java 应用程序的其他所有线程都被挂起（除了垃圾收集帮助器之外）。Java 中一种全局暂停现象，全局停顿，所有 Java 代码停止，native 代码可以执行，但不能与 JVM 交互。 为什么需要STW 在 java 应用程序中引用关系是不断发生变化的，那么就会有会有很多种情况来导致垃圾标识出错。想想一下如果 Object a 目前是个垃圾，GC 把它标记为垃圾，但是在清除前又有其他对象指向了 Object a，那么此刻 Object a 又不是垃圾了，那么如果没有 STW 就要去无限维护这种关系来去采集正确的信息。 垃圾回收器是怎样寻找 GC Roots 的？ 我们在前面说明了根可达算法是通过 GC Roots 来找到存活的对象的，也定义了 GC Roots，那么垃圾回收器是怎样寻找GC Roots 的呢？首先，为了保证结果的准确性，GC Roots枚举时是要在STW的情况下进行的，但是由于 JAVA 应用越来越大，所以也不能逐个检查每个对象是否为 GC Root，那将消耗大量的时间。一个很自然的想法是，能不能用空间换时间，在某个时候把栈上代表引用的位置全部记录下来，这样到真正 GC 的时候就可以直接读取，而不用再一点一点的扫描了。事实上，大部分主流的虚拟机也正是这么做的，比如 HotSpot ，它使用一种叫做 OopMap 的数据结构来记录这类信息 OopMap是做什么的？有什么好处？ 我们知道，一个线程意味着一个栈，一个栈由多个栈帧组成，一个栈帧对应着一个方法，一个方法里面可能有多个安全点。gc 发生时，程序首先运行到最近的一个安全点停下来，然后更新自己的 OopMap ，记下栈上哪些位置代表着引用。枚举根节点时，递归遍历每个栈帧的 OopMap ，通过栈中记录的被引用对象的内存地址，即可找到这些对象（ GC Roots ）。使用 OopMap 可以避免全栈扫描，加快枚举根节点的速度。但这并不是它的全部用意。它的另外一个更根本的作用是，可以帮助 HotSpot 实现准确式 GC (即使用准确式内存管理，虚拟机可用知道内存中某个位置的数据具体是什么类型) 。 什么是安全点？ 从线程角度看，安全点可以理解成是在代码执行过程中的一些特殊位置，当线程执行到这些位置的时候，说明虚拟机当前的状态是安全的。比如：方法调用、循环跳转、异常跳转等这些地方才会产生安全点。如果有需要，可以在这个位置暂停，比如发生GC时，需要暂停所有活动线程，但是线程在这个时刻，还没有执行到一个安全点，所以该线程应该继续执行，到达下一个安全点的时候暂停，等待 GC 结束。那么如何让线程在垃圾回收的时候都跑到最近的安全点呢？这里有两种方式： 抢先式中断：就是在stw的时候，先让所有线程完全中断，如果中断的地方不在安全点上，然后再激活，直到运行到安全点的位置再中断。 主动式中断：在安全点的位置打一个标志位，每个线程执行都去轮询这个标志位，如果为真，就在最近的安全点挂起 安全区域是什么?解决了什么问题 刚刚说到了主动式中断,但是如果有些线程处于sleep状态怎么办呢？ 为了解决这种问题，又引入了安全区域的概念安全区域是指在一段代码片中，引用关系不会发生改变，实际上就是一个安全点的拓展。当线程执行到安全区域时，首先标识自己已进入安全区域，那样，当在这段时间里 JVM 要发起 GC 时，就不用管标识自己为“安全区域”状态的线程了，该线程只能乖乖的等待根节点枚举完或者整个GC过程完成之后才能继续执行。 垃圾回收器了解吗？年轻代和老年代都有哪些垃圾回收器？ Serial：单线程版本收集器，进行垃圾回收的时候会 STW（Stop The World），也就是进行垃圾回收的时候其他的工作线程都必须暂停。可以与 CMS 垃圾回收器一起搭配工作。 ParNew：Serial 的多线程版本，用于和 CMS 配合使用 Parallel Scavenge：可以并行收集的多线程垃圾收集器。采用复制算法负责新生代 是与 ParNew 类似，都是用于年轻代回收的使用复制算法的并行收集器，与 ParNew 不同的是，Parallel Scavenge 的目标是达到一个可控的吞吐量。吞吐量=程序运行时间/（程序运行时间+GC时间）。如程序运行了99s，GC耗时1s，吞吐量=99/（99+1）=99%。Parallel Scavenge 提供了两个参数用以精确控制吞吐量，分别是用以控制最大 GC 停顿时间的 -XX:MaxGCPauseMillis 及直接控制吞吐量的参数 -XX:GCTimeRatio.停顿时间越短就越适合需要与用户交互的程序，良好的响应速度能提升用户体验，而高吞吐量则可以高效的利用 CPU 时间，尽快完成程序的运算任务，主要适合在后台运算而不需要太多交互的任务。 Serial Old：Serial 的老年代版本，也是单线程。 Parallel Old：Parallel Scavenge 的老年代版本,可以与 Parallel Scavenge 垃圾回收器一起搭配工作 Parallel Old 是 Pararllel Scavenge 的老年代版本，它的设计思路也是以吞吐量优先的，ps+po 是很常用的一种组合。 CMSCMS（Concurrent Mark Sweep）：CMS 收集器是以获取最短停顿时间为目标的收集器。相对于其他的收集器 STW 的时间更短暂，可以并行收集是它的特点，同时它基于标记-清除算法。 初始标记：标记 GC ROOT 能关联到的对象，整个速度是非常快的，为了保证标记的准确，需要 STW； 并发标记：从 GCRoots 的直接关联对象开始遍历整个对象图的过程，这一部分时刻用户线程并发运行的，虽然耗时较长，但是不会有很大的影响，不需要 STW； 重新标记：为了修正并发标记期间，因用户程序继续运作而导致标记产生改变的标记，这里简单举个例子：并发标记时a没有被任何对象引用，此时垃圾回收器将该对象标位垃圾，在之后的标记过程中，a又被其他对象引用了，这时候如果不进行重新标记就会发生误清除，需要 STW； 并发清除：清理删除掉标记阶段判断的已经死亡的对象，这部分会和用户线程一起并发执行。不需要 STW CMS的三个缺点 影响用户线程的执行效率 CMS默认启动的回收线程数是（处理器核心数 + 3）/ 4 ,由于是和用户线程一起并发清理，那么势必会影响到用户线程的执行速度，并且这个影响随着核心线程数的递减而增加。所以 JVM 提供了一种 “增量式并发收集器“的 CMS 变种，主要是用来减少垃圾回收线程独占资源的时间，所以会感觉到回收时间变长，这样的话单位时间内处理垃圾的效率就会降低」也是一种缓和的方案。 会产生”浮动垃圾 之前说到 CMS 真正清理垃圾是和用户线程一起进行的，在清理这部分垃圾的时候用户线程会产生新的垃圾，这部分垃圾就叫做浮动垃圾，并且只能等着下一次的垃圾回收再清除 会产生碎片化的空间 CMS 是使用了标记删除的算法去清理垃圾的，而这种算法的缺点就是会产生碎片化，后续可能会导致大对象无法分配从而触发和 Serial Old 一起配合使用来处理碎片化的问题，当然这也处于 STW的情况下，所以当 java 应用非常庞大时，如果采用了 CMS 垃圾回收器，产生了碎片化，那么在 STW 来处理碎片化的时间会非常之久 G1 G1 垃圾回收器把堆划分成一个个大小相同的Region，每个 Region 都会扮演一个角色，H、S、E、O。E代表伊甸区，S代表 Survivor 区，H代表的是 Humongous(G1用来分配大对象的区域，对于 Humongous 也分配不下的超大对象，会分配在连续的 N 个 Humongous 中)，剩余的深蓝色代表的是 Old 区，白色的代表的是空闲的 region。在 HotSpot 的实现中，整个堆被划分成2048左右个 Region。每个 Region 的大小可以通过 -XX：G1HeapRegionSize 设置，大小为1~32M。，具体多大取决于堆的大小。在并发标记垃圾时也会产生新的对象，G1 对于这部分对象的处理是这样的：将 Region 新增一块并发回收过程中分配对象的空间，并为此设计了两个 TAMS(Top at Mark Start)指针，这块区域专门用来在并发时分配新对象，有对象新增只需要将 TAMS 指针移动下就可以了，并且这些新对象默认是标记为存活，这样就不会干扰到标记过程 但是这种方法也会有个问题，有可能垃圾回收的速度小于新对象分配的速度，这样会导致 “Full GC” 而产生长时间的 STW。在 G1 的设计理念里，最小回收单元是 Region，每次回收的空间大小都是Region的N倍，那么G1是怎么选择要回收哪块儿区域的呢？G1 会跟踪各个 Region 区域内的垃圾价值，和回收空间大小回收时间有关，然后维护一个优先级列表，来收集那些价值最高的Reigon区域。 G1 的回收过程分为以下四个步骤： 初始标记：标记 GC ROOT 能关联到的对象，修改 TAMS 的值以便于并发回收时新对象分配,需要 STW； 并发标记：从 GCRoots 的直接关联对象开始遍历整个对象图的过程，扫描完成后还会重新处理并发标记过程中产生变动的对象，记录 SATB(原始快照) 在并发时有引用的值； 最终标记：短暂暂停用户线程，再处理一次，处理第二步遗留下来的少量 SATB(原始快照) 记录，需要 STW； 筛选回收：更新 Region 的统计数据，对每个 Region 的回收价值和成本排序，根据用户设置的停顿时间制定回收计划。再把需要回收的 Region 中存活对象复制到空的 Region，同时清理旧的 Region。需要 STW。 说说三色标记 垃圾回收器标记垃圾的时候使用的算法 ,将对象分成三种颜色 白色：没被GC访问过的对象（被 GC 标记完后还是白色代表是垃圾） 黑色：存活的对象 灰色：被GC访问过的对象，但是对象引用链上至少还有一个引用没被扫描过 在并发标记的时候可能会出现误标的情况 刚开始标记为垃圾的对象，但是在并发标记过程中变为了存活对象 刚开始标记为存活的对象，但是在并发标记过程中变为了垃圾对象 第一种情况影响还不算很大，只是相当于垃圾没有清理干净，待下一次清理的时候再清理一下就好了。第二种情况就危险了，正在使 用的对象的突然被清理掉 了，后果会很严重。那么 产生上述第二种情况的原因 是什么呢？ 新增 一条或多条 黑色到白色 对象的新引用 删除 了 灰色 对象 到该白色对象 的直接 引用或间接引用。 当这两种情况 都满足 的时候就会出现这种问题了。所以为了解决这个问题，引入了 增量更新 (Incremental Update)和 原始快照 (SATB)的方案： 增量更新破坏了第一个条件：增加新引用时记录 该引用信息，在后续 STW 扫描中重新扫描(CMS的使用方案)。 原始快照破坏了第二个条件：删除引用时记录下来，在后续 STW 扫描时将这些记录过的灰色对象为根再扫描一次(G1的使用方案)。 什么情况下会发生栈内存溢出？Java 栈内存溢出可能抛出两种异常，两种异常虽然都发生在栈内存，但是两者导致内存溢出的根本原因是不一样的： 如果线程请求分配的栈容量超过 Java 虚拟机栈允许的最大容量的时候，Java 虚拟机将抛出一个 StackOverFlowError 异常。 如果 Java 虚拟机栈可以动态拓展，并且扩展的动作已经尝试过，但是目前无法申请到足够的内存去完成拓展，或者在建立新线程的时候没有足够的内存去创建对应的虚拟机栈，那 Java 虚拟机将会抛出一个 OutOfMemoryError 异常。 如何排查 OOM 的问题？ 增加两个参数 -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/tmp/heapdump.hprof，当 OOM 发生时自动 dump 堆内存信息到指定目录； 2.同时 jstat 查看监控 JVM 的内存和 GC 情况，先观察问题大概出在什么区域； 3.使用工具载入到 dump 文件，分析大对象的占用情况。 说一说类加载机制是什么?加载的过程又是怎么样的？介绍一下双亲委派模型,它的好处是什么 类加载机制 Java 虚拟机把描述类的数据从 Class 文件加载到内存，并对数据进行校验、转换解析和初始化，最终形成可以被 Jvm 可以直接使用的类型，这个过程就可以成为虚拟机的类加载机制。 类加载过程加载 将class文件加载至java虚拟机，并存储在方法区。方法区存储类信息、常量、静态变量 连接-验证 确保加载进来的class文件包含的信息是否符合java虚拟机的要求。是否合法、是否安全。验证项目包括：文件格式验证、元数据验证、字节码验证、符号引用验证。 连接-准备 为类变量分配内存，并设置类变量的初始值。 进行内存分配的包括类变量(static 修饰的变量),而不包括实例变量，实例变量将会在对象实例化时随着对象一起分配在java堆中。 其次是这里所说的初始值“通常情况”下是数据类型的零值（如0、0L、null、false等）。 连接-解析 将变量池里符号引用转为直接引用 初始化 初始化类变量、静态语句块。 在以下四种情况下初始化过程会被触发执行： 遇到new、getstatic、putstatic或invokestatic这4条字节码指令时，如果类没有进行过初始化，则需先触发其初始化； 使用java.lang.reflect包的方法对类进行反射调用的时候； 当初始化一个类的时候，如果发现其父类还没有进行过初始化、则需要先出发其父类的初始化； jvm启动时，用户指定一个执行的主类(包含main方法的那个类)，虚拟机会先初始化这个类 使用 使用类 卸载 执行了System.exit()方法 程序正常执行结束 程序在执行过程中遇到了异常或错误而异常终止 由于操作系统出现错误而导致Java虚拟机进程终止 真实情况是加载、验证、准备、初始化、卸载这五个阶段的顺序是确定的，是依次有序的。但是解析阶段有可能会在初始化之后才会进行，这是为了支持 Java 动态绑定的特性 动态绑定: 在运行时根据具体对象的类型进行绑定。提供了一些机制，可在运行期间判断对象的类型，并分别调用适当的方法。也就是说，编译器此时依然不知道对象的类型，但方法调用机制能自己去调查，找到正确的方法主体。 双亲委派模型 简而言之，就是说一个类加载器收到了类加载的请求，不会自己先加载，而是把它交给自己的父类去加载，层层迭代。 用上图来说明就是如果应用程序类加载器收到了一个类加载的请求，会先给扩展类加载器，然后再给启动类加载器，如果启动类加载器无法完成这个类加载的请求，再返回给扩展类加载器，如果扩展类加载器也无法完成，就返回给应用类加载器。 说一说对象的栈上分配吧 如果所有对象都分配在堆中那么会给 GC 带来许多不必要的压力,比如有些对象的生命周期只是在当前线程中，为了减少临时对象在堆内分配的数量，就可以在在栈上分配，随着线程的消亡而消亡。当然栈上空间必须充足,否则也无法分配，在判断是否能分配到栈上的另一条件就是要经过逃逸分析， 逃逸分析(Escape Analysis) 简单来讲就是：Java Hotspot 虚拟机判断这个新对象是否只会被当前线程引用，并且决定是否能够在 Java 堆上分配内存。 对象的内存布局是怎样的? 对象头: 对象头又分为 MarkWord 和 Class Pointer 两部分。 MarkWord:包含一系列的标记位，比如轻量级锁的标记位，偏向锁标记位,gc记录信息等等。 ClassPointer:用来指向对象对应的 Class 对象（其对应的元数据对象）的内存地址。在 32 位系统占 4 字节，在 64 位系统中占 8 字节。 Length:只在数组对象中存在，用来记录数组的长度，占用 4 字节 Instance data: 对象实际数据，对象实际数据包括了对象的所有成员变量，其大小由各个成员变量的大小决定。(这里不包括静态成员变量，因为其是在方法区维护的) Padding:Java 对象占用空间是 8 字节对齐的，即所有 Java 对象占用 bytes 数必须是 8 的倍数,是因为当我们从磁盘中取一个数据时，不会说我想取一个字节就是一个字节，都是按照一块儿一块儿来取的，这一块大小是 8 个字节，所以为了完整，padding 的作用就是补充字节，「保证对象是 8 字节的整数倍」。","link":"/%E5%85%AB%E8%82%A1%E6%96%87/JVM-%E5%8D%B7.html"},{"title":"mysql日志系统","text":"MySQL日志 说起MySQL的日志，有三种类型的日志对于MySQL来说是至关重要的，这三种日志分别为：Binlog、Undo Log 和 Redo Log。 Undo Log 日志 顾名思义，Undo Log的字面意思就是撤销操作的日志，指的是使MySQL中的数据回到某个状态。 Undo Log是一种 逻辑日志， 记录的是一个变化过程。比如，MySQL执行一个delete操作，Undo Log就会记录一个insert操作；MySQL执行一个insert操作，Undo Log就会记录一个delete操作；MySQL执行一个update操作，Undo Log就会记录一个相反的update操作。 Undo Log以段的方式来管理和记录日志信息，在InnoDB存储引擎的数据文件中，包含了一种叫做rollback segment的回滚段，其内部包含了1024个undo log senment。 作用 Undo Log对于MySQL实现事务来说，起着至关重要的作用，它实现了事务的原子性和多版本并发控制，也就是我们经常说的MVCC。 实现事务的原子性 Undo Log能够实现MySQL事务的原子性，在事务的处理过程中，如果MySQL出现了错误或者用户手动执行了事务的回滚操作（执行了rollback操作），MySQL可以利用Undo Log日志将数据库中的数据恢复到之前的状态。 实现MVCC机制 事务未提交前，Undo Log保存了未提交之前的版本数据，Undo Log中的数据可以作为旧版本数据的副本或者快照以便其他并发事务进行读取操作。 事务A手动开启事务后，对goods数据表中id为1的数据进行更新操作，首先会把更新命中的数据写入到Undo Buffer中。 在事务A未提交之前，此时，事务B手动开启事务，对goods数据表中的id为1的数据进行查询操作，此时的事务B会读取Undo Log中的数据并返回给客户端，这就是MySQL中的MVCC机制。 可以在MySQL中通过下面的命令来查看控制Undo Log日志的参数 1show variables like '%innodb_undo%'; Redo Log日志 Redo Log的字面意思就是重做日志，指的是在数据库出现意外情况时能够对重新执行某种操作。在MySQL中，事务中修改的任何数据，都会将最新的数据写入Redo Log中进行备份 在MySQL中，随着事务操作的执行，就会产生Redo Log日志，在事务提交时会产生Redo Log并将其写入Redo Buffer，Redo Buffer也并不是随着事务的提交就会被立刻写入到磁盘中，而是等事务操作的脏页写入到磁盘之后，Redo Log的使命也就完成了，此时，Redo Log日志占用的空间可以重新利用，会被后续产生的Redo Log日志覆盖 Redo Log 的原理 Redo Log 能够实现事务的持久性，防止在发生故障的时间点，有脏页未写入表的 ibd 文件中，在重启 MySQL 服务的时候，根据 Redo Log 进行重做，从而将未提交的事务进行持久化。这个过程可以简化为下图所示。 Redo Log 的写机制Redo Log文件的内容是以顺序循环的方式写入文件的，写满时就会回到第一个文件，进行覆盖写。 Write Pos 是当前记录的位置，一边写一边后移，写到最后一个文件末尾后就回到 0 号文件开头； CheckPoint是当前要擦除的位置，也是往后推移并且循环的，擦除记录前要把记录更新到数 据文件； Write Pos 和 CheckPoint之间还空着的部分，可以用来记录新的操作。如果 Write Pos 追上 CheckPoint，表示已经写满，此时就需要向后移动CheckPoint来擦除数据。 每个InnoDB存储引擎至少有1个重做日志文件组（group），每个文件组至少有2个重做日志文件，默认为ib_logfile0和ib_logfile1 。 可以在MySQL中通过如下命令来查看控制Redo Log的参数。 1show variables like '%innodb_log%'; Redo Log 写入机制 在Redo Log日志信息从Redo Buffer持久化到Redo Log时，具体的持久化策略可以通过innodb_flush_log_at_trx_commit 参数进行设置，具体策略如下所示。 0：每秒提交 Redo buffer -&gt;OS cache -&gt; flush cache to disk，可能丢失一秒内的事务数据。由后台Master线程每隔 1秒执行一次操作。 1（默认值）：每次事务提交执行 Redo Buffer -&gt; OS cache -&gt; flush cache to disk，这种方式最安全，性能最差。 2：每次事务提交执行 Redo Buffer -&gt; OS cache，然后由后台Master线程再每隔1秒执行OS cache -&gt; flush cache to disk 的操作。 一般建议选择取值2，因为 MySQL 挂了数据没有损失，整个服务器挂了才会损失1秒的事务提交数据。 Binlog 日志 Binlog记录所有MySQL数据库表结构变更以及表数据修改的二进制日志，不会记录select和show这类查询操作的日志。Binlog日志是以事件形式记录，还包含语句所执行的消耗时间。开启Binlog日志有以下两个最重要的使用场景。 主从复制：在主库中开启Binlog功能，这样主库就可以把Binlog传递给从库，从库拿到Binlog后实现数据恢复达到主从数据一致性。 数据恢复：通过mysqlbinlog等工具来恢复数据 Binlog 文件记录模式 Binlog文件记录模式有STATEMENT、ROW和MIXED三种， ROW 模式 ROW（row-based replication, RBR）：日志中会记录每一行数据被修改的情况，然后在slave端对相同的数据进行修改。 优点：能清楚记录每一个行数据的修改细节，能完全实现主从数据同步和数据的恢复。 缺点：批量操作，会产生大量的日志，尤其是alter table会让日志暴涨 STATMENT 模式 STATMENT（statement-based replication, SBR）：每一条被修改数据的SQL都会记录到master的Binlog中，slave在复制的时候SQL进程会解析成和原来master端执行过的相同的SQL再次执行。简称SQL语句复制。 优点：日志量小，减少磁盘IO，提升存储和恢复速度 缺点：在某些情况下会导致主从数据不一致，比如last_insert_id()、now()等函数。 MIXED模式 MIXED（mixed-based replication, MBR）：以上两种模式的混合使用，一般会使用STATEMENT模式保存binlog，对于STATEMENT模式无法复制的操作使用ROW模式保存binlog，MySQL会根据执行的SQL语句选择写入模式 。 Bingo 写机制 根据记录模式和操作触发event事件生成log event（事件触发执行机制）。 将事务执行过程中产生的日志时间（log event）写入缓冲区，每个事务线程都有一个缓冲区。Log Event保存在一个binlog_cache_mngr数据结构中，在该结构中有两个缓冲区，一个是stmt_cache，用于存放不支持事务的信息；另一个是trx_cache，用于存放支持事务的信息。 事务在提交阶段会将产生的log event写入到外部binlog文件中。不同事务以串行方式将log event写入Binlog文件中，所以一个事务包含的log event信息在binlog文件中是连续的，中间不会插入其他事务的log event。 Binlog文件操作Binlog状态查看1show variables like 'log_bin'; 开启Binlog功能，需要修改my.cnf或my.ini配置文件，在[mysqld]下面增加log_bin=mysql_bin_log，重启 MySQL服务。 12binlog-format=ROWlog-bin=mysqlbinlog 使用show binlog events命令1234show binary logs; //等价于show master logs;show master status;show binlog events;show binlog events in 'mysqlbinlog.000001'; 使用mysqlbinlog 命令12mysqlbinlog &quot;文件名&quot;mysqlbinlog &quot;文件名&quot; &gt; &quot;test.sql&quot; 使用 binlog 恢复数据12345//按指定时间恢复mysqlbinlog --start-datetime=&quot;2021-02-28 18:00:00&quot; --stopdatetime=&quot;2021-03-01 00:00:00&quot; mysqlbinlog.000001 | mysql -uroot -p123456//按事件位置号恢复mysqlbinlog --start-position=1789 --stop-position=2674 mysqlbinlog.000001| mysql -uroot -p123456 删除Binlog文件123purge binary logs to 'mysqlbinlog.000001'; //删除指定文件purge binary logs before '2021-03-01 00:00:00'; //删除指定时间之前的文件reset master; //清除所有文件 可以通过设置expire_logs_days参数来启动自动清理功能。默认值为0表示没启用。设置为大于0的整数表示超出多少天binlog文件会自动清除。","link":"/mysql/mysql%E6%97%A5%E5%BF%97%E7%B3%BB%E7%BB%9F.html"},{"title":"数据库中事务的几种隔离级别","text":"4种现象与4种隔离级别 关系型数据库在正常的使用过程中，也存在一些并发的场景。而一出现并发，就会出现各种各样的问题，例如：脏写、脏读、不可重复读、幻读，这都是些啥呢？下面一一具体举例解释。 脏写现象与读未提交(read uncommitted)隔离级别 事务 A 和事务 B 同时执行，它们都要对同一条数据进行修改(这条数据的值，假设为 data)。 首先是事务 A 将数据的值修改为 data1，暂时不提交事务； 然后事务 B 将数据的值修改为 data2，然后立马提交事务； 事务 A 可能由于自己的业务系统出现了异常，因此进行回滚操作，将数据的值重新回滚为 data。 在这个过程中，事务 A 一个回滚操作，将事务 B 修改的值也回滚了，一夜回到解放前，事务 B 白忙活一场，这种现象叫做脏写。它的本质就是一个事务将另一个事务提交的修改操作回滚了。 显然在数据库中，肯定不允许这种现象存在。那么该如何解决这种问题呢？加个写锁就能解决，要对数据修改，必须要先获取到这行数据的写锁，否则不能修改。 在事务 A 开启时，对 data 加上写锁，直到事务 A 提交事务以后，才释放锁，在此期间，其他事务由于获取不到锁，也就谈不上对 data 数据进行修改了。 在实际的数据库中，则是将事务的隔离级别设置为读未提交(read uncommitted) ，在该隔离级别下，能保证事务提交之前，其他事务不能同时对这条数据进行修改。 脏读现象与读提交(read committed)隔离级别 事务 A 和事务 B 同时执行，事务 A 先将数据从 data 修改为 data1，然后暂时不提交事务，而是继续向后处理业务逻辑。 然后事务 B 读取这一行数据，读取到值为 data1，然后基于 data1 这个值去处理自己的业务逻辑了。 接着事务 A 在处理后面的业务逻辑时出现了异常，因此要进行回滚操作，将数据从 data1 回滚为 data。 在这个过程中，当事务 B 再去查询时发现数据的值为 data，这就蛋疼了，本来是基于 data1 这个值去做的业务逻辑处理，结果现在发现值却是 data，完蛋了，全 NM 错了，这种现象就是脏读，它的本质就是一个事务读到了另一个事务未提交的值。 为了解决脏读的问题，数据库中定义了读提交(read committed) 隔离级别，它的意思就是，在读数据的时候，只能读到别的事务提交过后的值，对于未提交的事务对数据所做的修改操作，当前事务是无法读取到的。 在读提交的事务隔离级别下，当事务 B 去读取数据时，发现事务 A 还没有提交，因此它不能读取到 data1 这个值，只能读取到 data 这个值。 不可重复读现象与可重复读(repeatable read)隔离级别 假设现在数据库中事务的隔离级别为读提交，也就是未提交的事务修改的值，其他事务是读取不到的，那么在当前事务隔离级别下还会有其他问题吗？ 事务 A 和事务 B 同时开启事务，事务 A 先从数据库查询数据，读取到的值为 data，然后事务 A 先不提交事务。 接着事务 B 修改数据，将数据的值从 data 修改为 data1。 如果事务 B 先不提交事务，那么事务 A 此时来读取数据时，能读取到最新的值 data1 吗？不能，因为我们假设了此时事务的隔离级别处于读提交状态。 好，既然不能事务 A 不能读取到最新值，那么现在事务 B 提交事务，接着让事务 A 再次从数据库查询数据，此时能读取到最新的值吗？ 能，此时读取到的值为 data1，因为事务 B 已经提交了事务，在读提交的隔离级别下，提交了的事务，其他事务都能读取到最新的值。 但是这有问题啊！在同一个事务内（事务 A），它读取了两次数据，发现前后两次读取到的值分别是 data 和 data1，同一行数据，读到的值却不一样. 实际上这就是不可重复读现象，它的本质就是在同一个事务内，多次从数据库读取数据，读取到的值不一样。（注意不可重复读与脏读的区别：脏读是指读到了未提交事务的值，不可重复读指的是其他事务更新数据并提交后，自己前后读取到的数据不一致） 因此，可重复读(repeatable read) 事务隔离级别出现了，它的意思是，在同一个事务内，例如事务 A，多次从数据库读取数据时，每次读取到的值是一样的，即使在此期间有其他事务修改了这条数据的值，也不会导致事务 A 前后两次读取到的值不一样。 幻读现象与串行化(serializable)隔离级别假设事务 A 和事务 B 并发执行，首先事务 A 先执行了如下 SQL，假设查到了 1 条数据 12### 假设只查询出来一条数据select * from t where id &gt; 1 接着事务 B 向数据库中又新插入了 10 条数据，并提交了事务； 然后事务 A 又使用同样的 SQL 语句查询数据，这时会查询出来 11 条数据，比之前查出来的数据多，也就是说看到了更多的数据，这种现象就是幻读。 注意幻读与不可重复读的区别：幻读特指在同一个事务内，前后两次查询，后面的查询，读到了之前没看到的数据；而不可重复读指的是在同一个事务内，针对同一行数据而言，前后两次查询，读取到的值不一样。 为了解决幻读的问题，数据库提出了串行化(Serializable) 这种事务隔离级别。 那么什么是串行化呢？归根结底，出现脏写、脏读、不可重复读、幻读这些问题，都是因为并发导致的，那要一下子全部解决这些问题，最简单的办法就是不要让线程并发执行，让多个线程一个一个执行，也就是串行化（也就是不让并发出现，都没有并发了，也就没有脏写、脏读、不可重复读、幻读这些幺蛾子了）。 总结由于事务的并发执行，会造成很多异常的现象，例如脏写、脏读、不可重复读、幻读等。 这四种现象总结起来就是： 脏写指的是一个事务将其他事务提交的修改回滚了； 脏读指的是一个事务读取到了另一个事务未提交的修改值； 不可重复读指的是一个事务对同一条数据，两次前后读取到的值不一样，这是因为在此期间有其他事务更新了该条数据； 幻读指的是一个事务，后一次的查询比前一次查询看到的数据多了，它特指读到了新的数据，需要与不可重复读的现象区分开来。 为了解决这些问题，SQL 标准（注意：这里说的是 SQL 标准）中定义了 4 种事务的隔离级来应对这些现象，分别是:读未提交、读提交、可重复读、串行化，它们的强度也依次递增。在这四种隔离级别下，它们的表现如下： 脏写 脏读 不可重复读 幻读 读未提交 ❌ ✅ ✅ ✅ 读提交 ❌ ❌ ✅ ✅ 可重复读 ❌ ❌ ❌ ✅ 串行化 ❌ ❌ ❌ ❌ 实际上，这四种事务的隔离级别只是 SQL 标准中定义的，在各大数据库中，这 4 种隔离级别在实现细节上又有所不同，例如：对于 MySQL 的 InnoDB 存储引擎而言，在可重复读隔离级别下，MySQL 通过 MVCC 机制解决了幻读的问题（在 SQL 标准中，可重复读隔离级别下仍存在幻读的问题）。","link":"/mysql/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%AD%E4%BA%8B%E5%8A%A1%E7%9A%84%E5%87%A0%E7%A7%8D%E9%9A%94%E7%A6%BB%E7%BA%A7%E5%88%AB.html"},{"title":"undo log版本链与ReadView机制“","text":"undo log 版本链 在 MySQL 的数据表中，存储着一行行的数据记录，对每行数据而言，不仅仅记录着我们定义的字段值，还会隐藏两个字段：row_trx_id 和 roll_pointer，前者表示更新本行数据的事务 id，后者表示的是回滚指针，它指向的是该行数据上一个版本的 undo log 当我们进行数据的新增、删除、修改操作时，会写 redo log(解决数据库宕机重启丢失数据的问题)和 binlog(主要用来做复制、数据备份等操作)，另外还会写 undo log，它是为了实现事务的回滚操作。 每一条 undo log 的具体内容可以自行网上查阅。我们只需要知道每行 undo log 日志会记录对应的事务 id，还会记录当前事务将数据修改后的最新值，以及指向当前行数据上一个版本的 undo log 的指针，也就是 roll_pointer。 为了方便理解，每一行 undo log 可以简化为下图所示的结构 举个例子，现在有一个事务 A，它的事务 id 为 10，向表中新插入了一条数据，数据记为 data_A，那么此时对应的 undo log 应该如下图所示： 接着事务 B(trx_id=20)，将这行数据的值修改为 data_B，同样也会记录一条 undo log，如下图所示，这条 undo log 的 roll_pointer 指针会指向上一个数据版本的 undo log，也就是指向事务 A 写入的那一行 undo log。 再接着，事务 C(trx_id=30)，将这行数据的值修改为 data_C，对应的示意图如下。 只要有事务修改了这一行的数据，那么就会记录一条对应的 undo log，一条 undo log 对应这行数据的一个版本，当这行数据有多个版本时，就会有多条 undo log 日志，undo log 之间通过 roll_pointer 指针连接，这样就形成了一个 undo log 版本链 ReadView机制当事务在开始执行的时候，会给每个事务生成一个 ReadView。这个 ReadView 会记录 4 个非常重要的属性 creator_trx_id: 当前事务的 id； m_ids: 当前系统中所有的活跃事务的 id，活跃事务指的是当前系统中开启了事务，但是还没有提交的事务； min_trx_id: 当前系统中，所有活跃事务中事务 id 最小的那个事务，也就是 m_id 数组中最小的事务 id； max_trx_id: 当前系统中事务的 id 值最大的那个事务 id 值再加 1，也就是系统中下一个要生成的事务 id。 ReadView 会根据这 4 个属性，再结合 undo log 版本链，来实现 MVCC 机制，决定让一个事务能读取到哪些数据，不能读取到哪些数据。 当一个事务读取某条数据时，就会按照如下规则来决定当前事务能读取到什么数据： 如果当前数据的 row_trx_id 小于 min_trx_id，那么表示这条数据是在当前事务开启之前，其他的事务就已经将该条数据修改了并提交了事务(事务的 id 值是递增的)，所以当前事务能读取到。 如果当前数据的 row_trx_id 大于等于 max_trx_id，那么表示在当前事务开启以后，过了一段时间，系统中有新的事务开启了，并且新的事务修改了这行数据的值并提交了事务，所以当前事务肯定是不能读取到的，因此这是后面的事务修改提交的数据。 如果当前数据的 row_trx_id 处于 min_trx_id 和 max_trx_id 的范围之间，又需要分两种情况： （a）row_trx_id 在 m_ids 数组中，那么当前事务不能读取到。为什么呢？row_trx_id 在 m_ids 数组中表示的是和当前事务在同一时刻开启的事务，修改了数据的值，并提交了事务，所以不能让当前事务读取到； （b) row_trx_id 不在 m_ids 数组中，那么当前事务能读取到。row_trx_id 不在 m_ids 数组中表示的是在当前事务开启之前，其他事务将数据修改后就已经提交了事务，所以当前事务能读取到。 注意：如果 row_trx_id 等于当前事务的 id，那表示这条数据就是当前事务修改的，那当前事务肯定能读取到啊。 先假设表中有一条数据，它的 row_trx_id=10，roll_pointer 为 null，那么此时 undo log 版本链就是下图这样： 假设现在有事务 A 和事务 B 并发执行，事务 A 的事务 id 为 20，事务 B 的事务 id 为 30。 那么此时对于事务 A 而言，它的 ReadView 中，m_ids=[20,30]，min_trx_id=20，max_trx_id=31，creator_trx_id=20。 对于事务 B 而言，它的 ReadView 中，m_ids=[20,30]，min_trx_id=20，max_trx_id=31，creator_trx_id=30。 如果此时事务 A(trx_id=20)去读取数据，那么在 undo log 版本链中，数据最新版本的事务 id 为 10，这个值小于事务 A 的 ReadView 里 min_trx_id 的值，这表示这个数据的版本是事务 A 开启之前，其他事务提交的，因此事务 A 可以读取到，所以读取到的值是 data0。 接着事务 B(trx_id=30)去修改数据，将数据修改为 data_B，先不提交事务。虽然不提交事务，但是仍然会记录一条 undo log，因此这条数据的 undo log 的版本链就有两条记录了，新的这条 undo log 的 roll_pointer 指针会指向前一条 undo log，示意图如下。 接着事务 A(trx_id=20)去读取数据，那么在 undo log 版本链中，数据最新版本的事务 id 为 30，这个值处于事务 A 的 ReadView 里 min_trx_id 和 max_trx_id 之间，因此还需要判断这个数据版本的值是否在 m_ids 数组中，结果发现，30 确实在 m_ids 数组中，这表示这个版本的数据是和自己同一时刻启动的事务修改的，因此这个版本的数据，数据 A 读取不到。所以需要沿着 undo log 的版本链向前找，接着会找到该行数据的上一个版本，也就是 trx_id=10 的版本，由于这个版本的数据的 trx_id=10，小于 min_trx_id 的值，因此事务 A 能读取到该版本的值，即事务 A 读取到的值是 data0。 紧接着事务 B 提交事务，那么此时系统中活跃的事务就只有 id 为 20 的事务了，也就是事务 A。那么此时事务 A 再去读取数据，它能读取到什么值呢？还是 data0。为什么呢？ 虽然系统中当前只剩下 id 为 20 的活跃事务了，但是事务 A 开启的瞬间，它已经生成了 ReadView ，后面即使有其他事务提交了，但是事务 A 的 ReadView 不会修改，也就是 m_ids 不会变，还是 m_ids=[20,30]，所以此时事务 A 去根据 undo log 版本链去读取数据时，还是不能读取最新版本的数据，只能往前找，最终还是只能读取到 data0。 接着系统中，新开了一个事务 C，事务 id 为 40，它的 ReadView 中，m_ids=[20,40]，min_trx_id=20，max_trx_id=41，creator_trx_id=40。 然后事务 C(trx_id=40)将数据修改为 data_C，并提交事务。此时 undo log 版本链就变成了如下图所示 此时事务 A(trx_id=20)去读取数据，那么在 undo log 版本链中，数据最新版本的事务 id 为 40，由于此时事务 A 的 ReadView 中的 max_trx_id=31，40 大于 31，这表示当前版本的数据时在事务 A 之后提交的，因此对于事务 A 肯定是不能读取到的。所以此时事务 A 只能根据 roll_pointer 指针，沿着 undo log 版本向前找，结果发现上一个版本的 trx_id=30，自己还是不能读取到，所以再继续往前找，最终可以读取到 trx_id=10 的版本数据，因此最终事务 A 只能读取到 data0。 接着事务 A(trx_id=20)去修改数据，将数据修改为 data_A，那么就会记录一条 undo log，示意图如下： 然后事务 A(trx_id=20)再去读取数据，在 undo log 版本链中，数据最新版本的事务 id 为 20，事务 A 一对比，发现该版本的事务 id 与自己的事务 id 相等，这表示这个版本的数据就是自己修改的，既然是自己修改的，那就肯定能读取到了，因此此时读取到是 data_A。 如何通过MVCC来解决不可重复读和幻读不可重复度 参照上面ReadView的机制讲解的例子，这里补充一下 事务 A 的 ReadView 是在发起第一次查询的时候创建的，当时系统中的活跃事务有 20 和 30 这两个 id，那么此时当事务 B 提交以后，事务 A 的 ReadView 的 m_ids 会变化吗？不会。因为是可重复读隔离级别下，对于读事务，只会在事务查询的第一次创建 ReadView，后面的查询不会再重新创建 幻读 幻读特指后面的查询比前面的查询的记录条数多，看到了前面没看到的数据，就像产生幻觉一样，因此称之为幻读。 (补)快照读与当前读 在解释 MySQL 的可重复读隔离级别解决了幻读问题之前，我们先来看两个定义：「快照读与当前读」。 我们知道，在事务开启的时候，会基于当前系统中数据库的数据，为每个事务生成一个快照，也叫做 ReadView，后面这个事务所有的读操作都是基于这个 ReadView 来读取数据，这种读称之为快照读。「我们在实际的工作中，所使用的 SQL 查询语句基本都是快照读。」 通过前面介绍的 undo log 版本链，我们知道，每行数据可能会有多个版本，如果每次读取时，「我们都强制性的读取最新版本的数据，这种读称之为当前读，也就是读取最新的数据」。什么样的 SQL 查询语句叫做当前读呢？例如在 select 语句后面加上「for update 或者 lock in share mode」等 1234# 加上排他锁select * from t for update;# 加上共享锁select * from t for lock in share mode; 可以发现，当前读的这两种写法，在查询过程中都是需要加锁的，因此它们能读取到最新的数据。 在 MySQL 可重复读隔离级别下，幻读问题确实不存在。但是 MVCC 机制解决的是快照读的幻读问题，并不能解决当前读的幻读问题。当前读的幻读问题是通过间隙锁解决的 以下是基于快照读来进行解读 假设现在表 t 中只有一条数据，数据内容中，主键 id=1，隐藏的 trx_id=10，它的 undo log 如下图所示 假设现在有事务 A 和事务 B 并发执行，事务 A 的事务 id 为 20，事务 B 的事务 id 为 30。 现在事务 A 开始第一次查询数据，查询的 SQL 语句如下。 1select * from where id &gt;= 1; 在开始查询之前，MySQL 会为事务 A 产生一个 ReadView，此时 ReadView 的内容如下：m_ids=[20,30]，min_trx_id=20，max_trx_id=31，creator_trx_id=20。 由于此时表 t 中只有一条数据，且符合 where id&gt;=1 条件，因此会查询出来。然后通过 ReadView 机制，发现该行数据的 row_id=10，小于事务 A 的 ReadView 里 min_trx_id，这表示这条数据是事务 A 开启之前，其他事务就已经提交了的数据，因此事务 A 可以读取到。 接着事务 B(trx_id=30)，往表 t 中新插入两条数据，SQL 语句如下。 12insert into t(id,name) values(2,'小明');insert into t(id,name) values(3,'小红'); 然后事务提交事务，那么此时表 t 中就有三条数据了，对应的 undo 如下图所示： 接着事务 A 开启第二次查询，根据可重复读隔离级别的规则，此时事务 A 并不会再重新生成 ReadView。此时表 t 中的 3 条数据都满足 where id&gt;=1 的条件，因此会先查出来，然后再根据 ReadView 机制，判断每条数据是不是都可以被事务 A 看到。 首先 id=1 的这条数据，前面已经说过了，可以被事务 A 看到。 然后是 id=2 的数据，它的 trx_id=30，此时事务 A 发现，这个值处于 min_trx_id 和 max_trx_id 之间，因此还需要再判断 30 是否处于 m_ids 数组内。由于事务 A 的 m_ids=[20,30]，因此在数组内，这表示 id=2 的这条数据是与事务 A 在同一时刻启动的其他事务提交的，所以这条数据不能让事务 A 看到。 同理，id=3 的这条数据，trx_id 也为 30，因此也不能被事务 A 看见。 结论：最终事务 A 的第二次查询，只能查询出 id=1 的这条数据。这和事务 A 的第一次查询的结果是一样的，因此没有出现幻读现象，所以说在 MySQL 的可重复读隔离级别下，不存在幻读问题。","link":"/mysql/undo-log%E7%89%88%E6%9C%AC%E9%93%BE%E4%B8%8EReadView%E6%9C%BA%E5%88%B6%E2%80%9C.html"},{"title":"Java内存模型(JMM)","text":"Java虚拟机规范中定义了Java内存模型（Java Memory Model，JMM），用于屏蔽掉各种硬件和操作系统的内存访问差异，以实现让Java程序在各种平台下都能达到一致的并发效果，JMM规范了Java虚拟机与计算机内存是如何协同工作的：规定了一个线程如何和何时可以看到由其他线程修改过后的共享变量的值，以及在必须时如何同步的访问共享变量。 Java内存模型（不仅仅是JVM内存分区）：调用栈和本地变量存放在线程栈上，对象存放在堆上。 一个本地变量可能是原始类型，在这种情况下，它总是“呆在”线程栈上 一个本地变量也可能是指向一个对象的一个引用。在这种情况下，引用（这个本地变量）存放在线程栈上，但是对象本身存放在堆上。 一个对象可能包含方法，这些方法可能包含本地变量。这些本地变量仍然存放在线程栈上，即使这些方法所属的对象存放在堆上。 一个对象的成员变量可能随着这个对象自身存放在堆上。不管这个成员变量是原始类型还是引用类型。 静态成员变量跟随着类定义一起也存放在堆上。 存放在堆上的对象可以被所有持有对这个对象引用的线程访问。当一个线程可以访问一个对象时，它也可以访问这个对象的成员变量。如果两个线程同时调用同一个对象上的同一个方法，它们将会都访问这个对象的成员变量，但是每一个线程都拥有这个成员变量的私有拷贝 硬件内存架构 现代硬件内存模型与Java内存模型有一些不同，理解内存模型架构以及Java内存模型如何与它协同工作也是非常重要的。 现代计算机硬件架构的简单图示 多CPU：一个现代计算机通常由两个或者多个CPU。其中一些CPU还有多核。从这一点可以看出，在一个有两个或者多个CPU的现代计算机上同时运行多个线程是可能的。每个CPU在某一时刻运行一个线程是没有问题的。这意味着，如果你的Java程序是多线程的，在你的Java程序中每个CPU上一个线程可能同时（并发）执行。 CPU寄存器：每个CPU都包含一系列的寄存器，它们是CPU内内存的基础。CPU在寄存器上执行操作的速度远大于在主存上执行的速度。这是因为CPU访问寄存器的速度远大于主存。 高速缓存cache：由于计算机的存储设备与处理器的运算速度之间有着几个数量级的差距，所以现代计算机系统都不得不加入一层读写速度尽可能接近处理器运算速度的高速缓存（Cache）来作为内存与处理器之间的缓冲：将运算需要使用到的数据复制到缓存中，让运算能快速进行，当运算结束后再从缓存同步回内存之中，这样处理器就无须等待缓慢的内存读写了。CPU访问缓存层的速度快于访问主存的速度，但通常比访问内部寄存器的速度还要慢一点。每个CPU可能有一个CPU缓存层，一些CPU还有多层缓存。在某一时刻，一个或者多个缓存行（cache lines）可能被读到缓存，一个或者多个缓存行可能再被刷新回主存。 内存：一个计算机还包含一个主存。所有的CPU都可以访问主存。主存通常比CPU中的缓存大得多。 运作原理：通常情况下，当一个CPU需要读取主存时，它会将主存的部分读到CPU缓存中。它甚至可能将缓存中的部分内容读到它的内部寄存器中，然后在寄存器中执行操作。当CPU需要将结果写回到主存中去时，它会将内部寄存器的值刷新到缓存中，然后在某个时间点将值刷新回主存 上述模型会带来一些问题：（多线程环境下尤其） 缓存一致性问题：在多处理器系统中，每个处理器都有自己的高速缓存，而它们又共享同一主内存（MainMemory）。基于高速缓存的存储交互很好地解决了处理器与内存的速度矛盾，但是也引入了新的问题：缓存一致性（CacheCoherence）。当多个处理器的运算任务都涉及同一块主内存区域时，将可能导致各自的缓存数据不一致的情况，如果真的发生这种情况，那同步回到主内存时以谁的缓存数据为准呢？为了解决一致性的问题，需要各个处理器访问缓存时都遵循一些协议，在读写时要根据协议来进行操作，这类协议有MSI、MESI（IllinoisProtocol）、MOSI、Synapse、Firefly及DragonProtocol，等等 指令重排序问题：为了使得处理器内部的运算单元能尽量被充分利用，处理器可能会对输入代码进行乱序执行（Out-Of-Order Execution）优化，处理器会在计算之后将乱序执行的结果重组，保证该结果与顺序执行的结果是一致的，但并不保证程序中各个语句计算的先后顺序与输入代码中的顺序一致。因此，如果存在一个计算任务依赖另一个计算任务的中间结果，那么其顺序性并不能靠代码的先后顺序来保证。与处理器的乱序执行优化类似，Java虚拟机的即时编译器中也有类似的指令重排序（Instruction Reorder）优化 Java内存模型和硬件内存架构之间的桥接 Java内存模型与硬件内存架构之间存在差异。硬件内存架构没有区分线程栈和堆。对于硬件，所有的线程栈和堆都分布在主内存中。部分线程栈和堆可能有时候会出现在CPU缓存中和CPU内部的寄存器中。如下图所示： 从抽象的角度来看，JMM定义了线程和主内存之间的抽象关系: 线程之间的共享变量存储在主内存（Main Memory）中; 每个线程都有一个私有的本地内存（Local Memory），本地内存是JMM的一个抽象概念，并不真实存在，它涵盖了缓存、写缓冲区、寄存器以及其他的硬件和编译器优化。本地内存中存储了该线程以读/写共享变量的拷贝副本。 从更低的层次来说，主内存就是硬件的内存，而为了获取更好的运行速度，虚拟机及硬件系统可能会让工作内存优先存储于寄存器和高速缓存中。 Java内存模型中的线程的工作内存（working memory）是cpu的寄存器和高速缓存的抽象描述。而JVM的静态内存储模型（JVM内存模型）只是一种对内存的物理划分而已，它只局限在内存，而且只局限在JVM的内存。 Java内存模型的抽象结构图 线程、主内存、工作内存三者 的交互关系 、 JMM模型下的线程间通信 线程间通信必须要经过主内存。 关于主内存与工作内存之间的具体交互协议，即一个变量如何从主内存拷贝到工作内存、如何从工作内存同步到主内存之间的实现细节，Java内存模型定义了以下八种操作来完成： lock（锁定）：作用于主内存的变量，把一个变量标识为一条线程独占状态。 unlock（解锁）：作用于主内存变量，把一个处于锁定状态的变量释放出来，释放后的变量才可以被其他线程锁定。 read（读取）：作用于主内存变量，把一个变量值从主内存传输到线程的工作内存中，以便随后的load动作使用 load（载入）：作用于工作内存的变量，它把read操作从主内存中得到的变量值放入工作内存的变量副本中。 use（使用）：作用于工作内存的变量，把工作内存中的一个变量值传递给执行引擎，每当虚拟机遇到一个需要使用变量的值的字节码指令时将会执行这个操作。 assign（赋值）：作用于工作内存的变量，它把一个从执行引擎接收到的值赋值给工作内存的变量，每当虚拟机遇到一个给变量赋值的字节码指令时执行这个操作。 store（存储）：作用于工作内存的变量，把工作内存中的一个变量的值传送到主内存中，以便随后的write的操作。 write（写入）：作用于主内存的变量，它把store操作从工作内存中一个变量的值传送到主内存的变量中。 Java内存模型还规定了在执行上述八种基本操作时，必须满足如下规则： 如果要把一个变量从主内存中复制到工作内存，就需要按顺寻地执行read和load操作， 如果把变量从工作内存中同步回主内存中，就要按顺序地执行store和write操作。但Java内存模型只要求上述操作必须按顺序执行，而没有保证必须是连续执行。 不允许read和load、store和write操作之一单独出现 不允许一个线程丢弃它的最近assign的操作，即变量在工作内存中改变了之后必须同步到主内存中。 不允许一个线程无原因地（没有发生过任何assign操作）把数据从工作内存同步回主内存中。 一个新的变量只能在主内存中诞生，不允许在工作内存中直接使用一个未被初始化（load或assign）的变量。即就是对一个变量实施use和store操作之前，必须先执行过了assign和load操作。 一个变量在同一时刻只允许一条线程对其进行lock操作，但lock操作可以被同一条线程重复执行多次，多次执行lock后，只有执行相同次数的unlock操作，变量才会被解锁。lock和unlock必须成对出现 如果对一个变量执行lock操作，将会清空工作内存中此变量的值，在执行引擎使用这个变量前需要重新执行load或assign操作初始化变量的值 如果一个变量事先没有被lock操作锁定，则不允许对它执行unlock操作；也不允许去unlock一个被其他线程锁定的变量。 对一个变量执行unlock操作之前，必须先把此变量同步到主内存中（执行store和write操作） Java内存模型解决的问题 当对象和变量被存放在计算机中各种不同的内存区域中时，就可能会出现一些具体的问题。Java内存模型建立所围绕的问题：在多线程并发过程中，如何处理多线程读同步问题与可见性（多线程缓存与指令重排序）、多线程写同步问题与原子性（多线程竞争race condition）。 多线程读同步与可见性 可见性（共享对象可见性）：线程对共享变量修改的可见性。当一个线程修改了共享变量的值，其他线程能够立刻得知这个修改。 线程缓存导致的可见性问题： 如果两个或者更多的线程在没有正确的使用volatile声明或者同步的情况下共享一个对象，一个线程更新这个共享对象可能对其它线程来说是不可见的：共享对象被初始化在主存中。跑在CPU上的一个线程将这个共享对象读到CPU缓存中，然后修改了这个对象。只要CPU缓存没有被刷新会主存，对象修改后的版本对跑在其它CPU上的线程都是不可见的。这种方式可能导致每个线程拥有这个共享对象的私有拷贝，每个拷贝停留在不同的CPU缓存中 解决这个内存可见性问题你可以使用: Java中的volatile关键字：volatile关键字可以保证直接从主存中读取一个变量，如果这个变量被修改后，总是会被写回到主存中去。Java内存模型是通过在变量修改后将新值同步回主内存，在变量读取前从主内存刷新变量值这种依赖主内存作为传递媒介的方式来实现可见性的，无论是普通变量还是volatile变量都是如此，普通变量与volatile变量的区别是：volatile的特殊规则保证了新值能立即同步到主内存，以及每个线程在每次使用volatile变量前都立即从主内存刷新。因此我们可以说volatile保证了多线程操作时变量的可见性，而普通变量则不能保证这一点。 Java中的synchronized关键字：同步快的可见性是由“如果对一个变量执行lock操作，将会清空工作内存中此变量的值，在执行引擎使用这个变量前需要重新执行load或assign操作初始化变量的值”、“对一个变量执行unlock操作之前，必须先把此变量同步回主内存中（执行store和write操作）”这两条规则获得的。 Java中的final关键字：final关键字的可见性是指，被final修饰的字段在构造器中一旦被初始化完成，并且构造器没有把“this”的引用传递出去（this引用逃逸是一件很危险的事情，其他线程有可能通过这个引用访问到“初始化了一半”的对象），那么在其他线程就能看见final字段的值（无须同步） 重排序导致的可见性问题： Java程序中天然的有序性可以总结为一句话：如果在本地线程内观察，所有操作都是有序的（“线程内表现为串行”(Within-Thread As-If-Serial Semantics)）；如果在一个线程中观察另一个线程，所有操作都是无序的（“指令重排序”现象和“线程工作内存与主内存同步延迟”现象） Java语言提供了volatile和synchronized两个关键字来保证线程之间操作的有序性： volatile关键字本身就包含了禁止指令重排序的语义 synchronized则是由“一个变量在同一个时刻只允许一条线程对其进行lock操作”这条规则获得的，这个规则决定了持有同一个锁的两个同步块只能串行地进入 指令序列的重排序： 1）编译器优化的重排序。编译器在不改变单线程程序语义的前提下，可以重新安排语句的执行顺序。 2）指令级并行的重排序。现代处理器采用了指令级并行技术（Instruction-LevelParallelism，ILP）来将多条指令重叠执行。如果不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序。 3）内存系统的重排序。由于处理器使用缓存和读/写缓冲区，这使得加载和存储操作看上去可能是在乱序执行 多线程写同步与原子性多线程竞争（Race Conditions）问题 当读，写和检查共享变量时出现race conditions。 如果两个或者更多的线程共享一个对象，多个线程在这个共享对象上更新变量，就有可能发生race conditions。 如果线程A读一个共享对象的变量count到它的CPU缓存中。再想象一下，线程B也做了同样的事情，但是往一个不同的CPU缓存中。现在线程A将count加1，线程B也做了同样的事情。现在count已经被增加了两次，每个CPU缓存中一次。如果这些增加操作被顺序的执行，变量count应该被增加两次，然后原值+2被写回到主存中去。然而，两次增加都是在没有适当的同步下并发执行的。无论是线程A还是线程B将count修改后的版本写回到主存中取，修改后的值仅会被原值大1，尽管增加了两次 解决这个问题可以使用Java同步块。一个同步块可以保证在同一时刻仅有一个线程可以进入代码的临界区。同步块还可以保证代码块中所有被访问的变量将会从主存中读入，当线程退出同步代码块时，所有被更新的变量都会被刷新回主存中去，不管这个变量是否被声明为volatile。 使用原子性保证多线程写同步问题 原子性：指一个操作是按原子的方式执行的。要么该操作不被执行；要么以原子方式执行，即执行过程中不会被其它线程中断。 实现原子性： 由Java内存模型来直接保证的原子性变量操作包括read、load、assign、use、store、write，我们大致可以认为基本数据类型变量、引用类型变量、声明为volatile的任何类型变量的访问读写是具备原子性的（long和double的非原子性协定：对于64位的数据，如long和double，Java内存模型规范允许虚拟机将没有被volatile修饰的64位数据的读写操作划分为两次32位的操作来进行，即允许虚拟机实现选择可以不保证64位数据类型的load、store、read和write这四个操作的原子性，即如果有多个线程共享一个并未声明为volatile的long或double类型的变量，并且同时对它们进行读取和修改操作，那么某些线程可能会读取到一个既非原值，也不是其他线程修改值的代表了“半个变量”的数值。但由于目前各种平台下的商用虚拟机几乎都选择把64位数据的读写操作作为原子操作来对待，因此在编写代码时一般也不需要将用到的long和double变量专门声明为volatile）。这些类型变量的读、写天然具有原子性，但类似于 “基本变量++” / “volatile++” 这种复合操作并没有原子性。 如果应用场景需要一个更大范围的原子性保证，需要使用同步块技术。Java内存模型提供了lock和unlock操作来满足这种需求。虚拟机提供了字节码指令monitorenter和monitorexist来隐式地使用这两个操作，这两个字节码指令反映到Java代码中就是同步快——synchronized关键字。 as-if-serial 语义 不管怎么重排序（编译器和处理器为了提高并行度），（单线程）程序的执行结果不能被改变。（编译器、runtime和处理器都必须遵守as-if-serial语义） happens before 从JDK 5开始，Java使用新的JSR-133内存模型，JSR-133使用happens-before的概念来阐述操作之间的内存可见性：在JMM中，如果一个操作执行的结果需要对另一个操作可见（两个操作既可以是在一个线程之内，也可以是在不同线程之间），那么这两个操作之间必须要存在happens-before关系 程序顺序规则 同一个顺序执行流中，会按照程序代码的编写顺序执行代码，编写在前面的代码操作要 happens - before 编写在后面的代码操作 每个线程在执行指令的过程中都相当于是一条顺序执行流程：取指令，执行，指向下一条指令，取指令，执行。 监视器锁(monitor)规则 这条规则是对于同一个 monitor 来说，这个 monitor 的解锁（unlock）要 happens - before 后面对这个监视器的加锁（lock）。 比如下面这段代码 123456789101112class monitorLock { private int value = 0; public synchronized int getValue() { return value; } public synchronized void setValue(int value) { this.value = value; }} 在这段代码中，getValue 和 setValue 这两个方法使用了同一个 monitor 锁，假设 A 线程正在执行 getValue 方法，B 线程正在执行 setValue 方法。monitor 的原则会规定线程 B 对 value 值的修改，能够直接对线程 A 可见。如果 getValue 和 setValue 没有 synchronized 关键字进行修饰的话，则不能保证线程 B 对 value 值的修改，能够对线程 A 可见。 monitor 的规则对于 synchronized 语义和 ReentrantLock 中的 lock 和 unlock 的语义是一样的。 volatile变量规则 这是一条对 volatile 的规则，它说的是对一个 volatile 变量的写操作 happens - before 后续任意对这个变量的读操作。 这条规则其实就是在说 volatile 语义的规则，因为对 volatile 的写和读之间会增加 memory barrier ，也就是内存屏障。 内存屏障也叫做栅栏，它是一种底层原语。它使得 CPU 或编译器在对内存进行操作的时候, 要严格按照一定的顺序来执行, 也就是说在 memory barrier 之前的指令和 memory barrier 之后的指令不会由于系统优化等原因而导致乱序。 线程 start 规则 这条规则也是适用于同一个线程，对于相同线程来说，调用线程 start 方法之前的操作都 happens - before start 方法之后的任意操作。 这条原则也可以这样去理解：调用 start 方法时，会将 start 方法之前所有操作的结果同步到主内存中，新线程创建好后，需要从主内存获取数据。这样在 start 方法调用之前的所有操作结果对于新创建的线程都是可见的。 可以看到，线程 A 在执行 ThreadB.start 方法之前会对共享变量进行修改，修改之后的共享变量会直接刷新到内存中，然后线程 A 执行 ThreadB.start 方法，紧接着线程 B 会从内存中读取共享变量。 线程 join 规则 这条规则是对多条线程来说的：如果线程 A 执行操作 ThreadB.join() 并成功返回，那么线程 B 中的任意操作都 happens - before 于线程 A 从 ThreadB.join 操作成功返回。 假设有两个线程 s、t，在线程 s 中调用 t.join() 方法。则线程 s 会被挂起，等待 t 线程运行结束才能恢复执行。当t.join() 成功返回时，s 线程就知道 t 线程已经结束了。所以根据本条原则，在 t 线程中对共享变量的修改，对 s 线程都是可见的。类似的还有 Thread.isAlive 方法也可以检测到一个线程是否结束。 线程传递规则 这是 happens - before 的最后一个规则，它主要说的是操作之间的传递性，也就是说，如果 A happens-before B，且 B happens-before C，那么 A happens-before C。 线程传递规则不像上面其他规则有单独的用法，它主要是和 volatile 规则、start 规则和 join 规则一起使用。 和volatile一起使用 比如现在有四个操作：普通写、volatile 写、volatile 读、普通读，线程 A 执行普通写和 volatile 写，线程B 执行volatile 读和普通读，根据程序的顺序性可知，普通写 happens - before volatile 写，volatile 读 happens - before 普通读，根据 volatile 规则可知，线程的 volatile 写 happens - before volatile 读和普通读，然后根据线程传递规则可知，普通写也 happens - before 普通读。","link":"/java/Java%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B-JMM.html"},{"title":"巧用 Bitmap 实现亿级海量数据统计","text":"在移动应用的业务场景中，我们需要保存这样的信息：一个 key 关联了一个数据集合。 常见的场景如下： 给一个 userId ，判断用户登陆状态； 显示用户某个月的签到次数和首次签到时间； 两亿用户最近 7 天的签到情况，统计 7 天内连续签到的用户总数； 通常情况下，我们面临的用户数量以及访问量都是巨大的，比如百万、千万级别的用户数量，或者千万级别、甚至亿级别的访问信息。 所以，我们必须要选择能够非常高效地统计大量数据（例如亿级）的集合类型。 如何选择合适的数据集合，我们首先要了解常用的统计模式，并运用合理的数据类型来解决实际问题。 二值状态统计；(本文介绍) 聚合统计； 排序统计； 基数统计。 指令可以通过在线 Redis 客户端运行调试，地址：https://try.redis.io/ 二值状态统计 也就是集合中的元素的值只有 0 和 1 两种，在签到打卡和用户是否登陆的场景中，只需记录签到(1)或 未签到(0)，已登录(1)或未登陆(0)。 假如我们在判断用户是否登陆的场景中使用 Redis 的 String 类型实现（key -&gt; userId，value -&gt; 0 表示下线，1 - 登陆），假如存储 100 万个用户的登陆状态，如果以字符串的形式存储，就需要存储 100 万个字符串了，内存开销太大。 为什么 String 类型内存开销大？ String 类型除了记录实际数据以外，还需要额外的内存记录数据长度、空间使用等信息。 当保存的数据包含字符串，String 类型就使用简单动态字符串（SDS）结构体来保存： len：占 4 个字节，表示 buf 的已用长度。 alloc：占 4 个字节，表示 buf 实际分配的长度，通常 &gt; len。 buf：字节数组，保存实际的数据，Redis 自动在数组最后加上一个 “\\0”，额外占用一个字节的开销。 所以，在 SDS 中除了 buf 保存实际的数据， len 与 alloc 就是额外的开销。 另外，还有一个 RedisObject 结构的开销，因为 Redis 的数据类型有很多，而且，不同数据类型都有些相同的元数据要记录（比如最后一次访问的时间、被引用的次数等）。 所以，Redis 会用一个 RedisObject 结构体来统一记录这些元数据，同时指向实际数据 对于二值状态场景，我们就可以利用 Bitmap 来实现。比如登陆状态我们用一个 bit 位表示，一亿个用户也只占用 一亿 个 bit 位内存 ≈ （100000000 / 8/ 1024/1024）12 MB。 什么是 Bitmap 呢？ Bitmap 的底层数据结构用的是 String 类型的 SDS 数据结构来保存位数组，Redis 把每个字节数组的 8 个 bit 位利用起来，每个 bit 位 表示一个元素的二值状态（不是 0 就是 1）。 可以将 Bitmap 看成是一个 bit 为单位的数组，数组的每个单元只能存储 0 或者 1，数组的下标在 Bitmap 中叫做 offset 偏移量。 为了直观展示，我们可以理解成 buf 数组的每个字节用一行表示，每一行有 8 个 bit 位，8 个格子分别表示这个字节中的 8 个 bit 位，如下图所示： 8 个 bit 组成一个 Byte，所以 Bitmap 会极大地节省存储空间。 这就是 Bitmap 的优势。 怎么用 Bitmap 来判断海量用户中某个用户是否在线呢？ Bitmap 提供了 GETBIT、SETBIT 操作，通过一个偏移值 offset 对 bit 数组的 offset 位置的 bit 位进行读写操作，需要注意的是 offset 从 0 开始。 只需要一个 key = login_status 表示存储用户登陆状态集合数据， 将用户 ID 作为 offset，在线就设置为 1，下线设置 0。通过 GETBIT判断对应的用户是否在线。50000 万 用户只需要 6 MB 的空间 SETBIT 命令 1SETBIT &lt;key&gt; &lt;offset&gt; &lt;value&gt; 设置或者清空 key 的 value 在 offset 处的 bit 值（只能是 0 或者 1）。 GETBIT 命令 1GETBIT &lt;key&gt; &lt;offset&gt; 获取 key 的 value 在 offset 处的 bit 位的值，当 key 不存在时，返回 0 假如我们要判断 ID = 10086 的用户的登陆情况： 第一步，执行以下指令，表示用户已登录。 1SETBIT login_status 10000 1 第二步，检查该用户是否登陆，返回值 1 表示已登录。 1GETBIT login_status 10000 第三步，登出，将 offset 对应的 value 设置成 0。 1SETBIT login_status 10000 0 案例用户每个月签到情况 在签到统计中，每个用户每天的签到用 1 个 bit 位表示，一年的签到只需要 365 个 bit 位。一个月最多只有 31 天，只需要 31 个 bit 位即可 比如统计编号10000的用户在 2021 年 5 月份的打卡情况要如何进行？ key 可以设计成 uid:sign:{userId}:{yyyyMM}，月份的每一天的值 - 1 可以作为 offset（因为 offset 从 0 开始，所以 offset = 日期 - 1） 第一步，执行下面指令表示记录用户在 2022 年 1 月 1号打卡。 1SETBIT uid:sign:10000:202101 1 1 第二步，判断用户10000在2022年1月1号是否打卡 1GETBIT uid:sign:10000:202101 1 第三步，统计该用户在一月份打卡的次数，使用BITCOUNT指令。该指令用于统计给定的 bit 数组中，值 = 1 的 bit 位的数量。 1BITCOUNT uid:sign:10000:202101 如何统计这个月首次打卡时间呢？ Redis 提供了 BITPOS key bitValue [start] [end]指令，返回数据表示 Bitmap 中第一个值为 bitValue 的 offset 位置。 在默认情况下， 命令将检测整个位图， 用户可以通过可选的 start 参数和 end 参数指定要检测的范围 1BITPOS uid:sign:10000:202101 1 需要注意的是，我们需要将返回的 value + 1 ，因为 offset 从 0 开始。 连续签到总数 在记录了一个亿的用户连续 7 天的打卡数据，如何统计出这连续 7 天连续打卡用户总数呢？ 我们把每天的日期作为 Bitmap 的 key，userId 作为 offset，若是打卡则将 offset 位置的 bit 设置成 1。 1SETBIT 20220101 1 1 key 对应的集合的每个 bit 位的数据则是一个用户在该日期的打卡记录。 一共有 7 个这样的 Bitmap，如果我们能对这 7 个 Bitmap 的对应的 bit 位做 『与』运算。 同样的 UserID offset 都是一样的，当一个 userID 在 7 个 Bitmap 对应对应的 offset 位置的 bit = 1 就说明该用户 7 天连续打卡。 结果保存到一个新 Bitmap 中，我们再通过 BITCOUNT 统计 bit = 1 的个数便得到了连续打卡 7 天的用户总数了。 Redis 提供了 BITOP operation destkey key [key ...]这个指令用于对一个或者多个 键 = key 的 Bitmap 进行位元操作。 opration 可以是 and、OR、NOT、XOR。当 BITOP 处理不同长度的字符串时，较短的那个字符串所缺少的部分会被看作 0 。空的 key 也被看作是包含 0 的字符串序列。 ps:这里演示连续的三天 1234567891011121314151617181920212223242526272829303132&gt; Setbit 20220101 1 10&gt; Setbit 20220102 1 10&gt; Setbit 20220103 1 10&gt; Setbit 20220101 2 10&gt; Setbit 20220102 2 10//与操作&gt; BITOP AND destmap 20220101 20220102 202201031// 统计 bit 位 = 1 的个数 //代表只有一个用户连续的&gt; BITCOUNT destmap1&gt; Setbit 20220103 2 10&gt; BITOP AND destmap 20220101 20220102 202201031&gt; BITCOUNT destmap2 总结 思路才是最重要，当我们遇到的统计场景只需要统计数据的二值状态，比如用户是否存在、 ip 是否是黑名单、以及签到打卡统计等场景就可以考虑使用 Bitmap。 只需要一个 bit 位就能表示 0 和 1。在统计海量数据的时候将大大减少内存占用。","link":"/redis/%E5%B7%A7%E7%94%A8-Bitmap-%E5%AE%9E%E7%8E%B0%E4%BA%BF%E7%BA%A7%E6%B5%B7%E9%87%8F%E6%95%B0%E6%8D%AE%E7%BB%9F%E8%AE%A1.html"}],"tags":[{"name":"mysql","slug":"mysql","link":"/tags/mysql/"},{"name":"redis","slug":"redis","link":"/tags/redis/"},{"name":"Netty","slug":"Netty","link":"/tags/Netty/"},{"name":"JVM","slug":"JVM","link":"/tags/JVM/"},{"name":"八股文","slug":"八股文","link":"/tags/%E5%85%AB%E8%82%A1%E6%96%87/"},{"name":"JAVA","slug":"JAVA","link":"/tags/JAVA/"},{"name":"JMM","slug":"JMM","link":"/tags/JMM/"}],"categories":[{"name":"Netty","slug":"Netty","link":"/categories/Netty/"},{"name":"Netty源码剖析","slug":"Netty/Netty源码剖析","link":"/categories/Netty/Netty%E6%BA%90%E7%A0%81%E5%89%96%E6%9E%90/"},{"name":"八股文","slug":"八股文","link":"/categories/%E5%85%AB%E8%82%A1%E6%96%87/"},{"name":"JVM","slug":"八股文/JVM","link":"/categories/%E5%85%AB%E8%82%A1%E6%96%87/JVM/"},{"name":"mysql","slug":"mysql","link":"/categories/mysql/"},{"name":"Java","slug":"Java","link":"/categories/Java/"},{"name":"redis","slug":"redis","link":"/categories/redis/"}]}