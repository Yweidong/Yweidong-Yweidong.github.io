{"pages":[{"title":"","text":"个人简介 分享很喜欢的老罗的一段话： “每一个生命来到世间都注定改变世界，别无选择。要么变得好一点，要么变得坏一点。你如果走进社会为了生存为了什么不要脸的理由，变成了一个恶心的成年人社会中的一员，那你就把这个世界变得恶心了一点点。如果你一生刚正不阿，如果你一生耿直，没有做任何恶心的事情，没做对别人有害的事情，一辈子拼了老命勉强把自己身边的几个人照顾好了，没有成名没有发财，没有成就伟大的事业，然后耿着脖子一生正直，到了七八十岁耿着脖子去世了。你这一生是不是没有改变世界？你还是改变世界了，你把这个世界变得美好了一点点。因为世界上又多了一个好人。“ 善恶终有报,天道好轮回。不信抬头看,苍天饶过谁。无论何时何地，我们都要保持一颗积极乐观、善良感恩的心。但行好事莫问前程，永远年轻，永远热内盈眶，永远保持正能量。💪💪💪💪💪💪冲鸭！！！！ -&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;个人信息：计算机科学与技术专业从事JAVA后端开发码畜一枚坚信代码改变世界 博客信息 网站采用的Icarus主题 追求尽可能的简洁，清晰，易用。 在Icarus主题之上进行了部分修改。 更新日志：–2020.09.20：icarus4.0适配–2020.01.18：icarus3.0适配–2019.11.17：增加深色主题开关–2019.10.30：去图，精简卡片–2019.10.22：改版部分显示，优化速度–2019.10.16：文章列表加上评论数显示–2019.10.13：改版评论–2019.09.25：图片、资源接入CDN免费jsDelivr、文章加入置顶–2019.09.19：开源博客代码–2019.09.19：修改布局，拉伸布局，更宽的展示–2019.09.18：修改友链ui为一行三个，并适配移动端，暗黑模式文章增加评论链接，增加留言链接–2019.09.14：增加精简next主题–2019.09.14：利用中秋节放假，重做了首页的热门推荐、加个widget最新评论框、归档页加入文章贡献概览面板 本站推荐索引 博客主题相关 github Issue 作为博客微型数据库的应用 github page网站cdn优化加速 博客源码分享 博客换肤的一种实现方式思路 博客中gitalk最新评论的获取 博客图片上传picgo工具github图传使用 安装、部分配置icarus主题中文版 技术知识点 Java并发知识点 法律法规 法律法规数据库 中华人民共和国国旗法 中华人民共和国宪法 中华人民共和国消费者权益保护法 中华人民共和国刑事诉讼法 中华人民共和国婚姻法 中华人名共和国网络安全法 中华人民共和国劳动法 其他 网易云音乐歌单分享 计划2020计划 2019.12.31 2020-GOALS 跑两三场马拉松 2019计划 2018.12.31/21:59:00-&gt;更新于2019.12.31 2019-GOALS 购买的专业书籍至少看完一遍（并发、重构、设计模式…）-&gt; 95% 额外： 追了很多剧 总结： 有优点有缺点，没坚持下来的还是太多，追了太多剧。以后多学习，多思考！ 时间轴记录","link":"/about/index.html"},{"title":"","text":"🎈🎈微笑墙🎈🎈 彭小苒 唐艺昕 李一桐 gakki 图片搜集于互联网，侵权请留言，马上处理😊。","link":"/album/index.html"},{"title":"","text":"&nbsp;&nbsp;听听音乐 音乐播放器由mePlayer提供，布局参照网友博客所作，感谢作者的辛勤付出。更多音乐分享请查看歌单。 &nbsp;&nbsp;看看视频 ->点击以下条目开始播放视频,向下滑动查看更多","link":"/media/index.html"},{"title":"","text":"来而不往非礼也畅所欲言，有留必应","link":"/message/index.html"},{"title":"","text":"申请友链须知 原则上只和技术类博客交换，但不包括含有和色情、暴力、政治敏感的网站。 不和剽窃、侵权、无诚信的网站交换，优先和具有原创作品的网站交换。 申请请提供：站点名称、站点链接、站点描述、logo或头像（不要设置防盗链）。 排名不分先后，刷新后重排，更新信息后请留言告知。 会定期清理很久很久不更新的、不符合要求的友链，不再另行通知。 本站不存储友链图片，如果友链图片换了无法更新。图片裂了的会替换成默认图，需要更换的请留言告知。 本站友链信息如下，申请友链前请先添加本站信息： 网站图标：https://removeif.github.io/images/avatar.jpg 网站名称：辣椒の酱 网站地址：https://removeif.github.io 网站简介：后端开发，技术分享 加载中，稍等几秒...","link":"/friend/index.html"},{"title":"音乐歌单收藏","text":"温馨提示：选择喜欢的音乐双击播放，由于版权原因部分不能播放。如果喜欢歌单收藏一下，去网易云都能播放哟！","link":"/music/index.html"},{"title":"","text":"碎碎念 tips：github登录后按时间正序查看、可点赞加❤️、本插件地址..「+99次查看」 碎碎念加载中，请稍等... $.getScript(\"/js/gitalk_self.min.js\", function () { var gitalk = new Gitalk({ clientID: '46a9f3481b46ea0129d8', clientSecret: '79c7c9cb847e141757d7864453bcbf89f0655b24', id: '666666', repo: 'issue_database', owner: 'removeif', admin: \"removeif\", createIssueManually: true, distractionFreeMode: false }); gitalk.render('comment-container1'); });","link":"/self-talking/index.html"}],"posts":[{"title":"Netty的整体架构脉络","text":"Netty 整体结构 Netty 是一个设计非常用心的网络基础组件，Netty 官网给出了有关 Netty 的整体功能模块结构，却没有其他更多的解释。从图中，我们可以清晰地看出 Netty 结构一共分为三个模块：(以下为官网图片) Core核心层 Core 核心层是 Netty 最精华的内容，它提供了底层网络通信的通用抽象和实现，包括可扩展的事件模型、通用的通信 API、支持零拷贝的 ByteBuf 等。 Protocol Support协议支持层 协议支持层基本上覆盖了主流协议的编解码实现，如 HTTP、SSL、Protobuf、压缩、大文件传输、WebSocket、文本、二进制等主流协议，此外 Netty 还支持自定义应用层协议。Netty 丰富的协议支持降低了用户的开发成本，基于 Netty 我们可以快速开发 HTTP、WebSocket 等服务。 TransportService 传输服务层 传输服务层提供了网络传输能力的定义和实现方法。它支持 Socket、HTTP 隧道、虚拟机管道等传输方式。Netty 对 TCP、UDP 等数据传输做了抽象和封装，用户可以更聚焦在业务逻辑实现上，而不必关系底层数据传输的细节。 Netty逻辑架构 下图是 Netty 的逻辑处理架构。Netty 的逻辑处理架构为典型网络分层架构设计，共分为网络通信层、事件调度层、服务编排层，每一层各司其职。图中包含了 Netty 每一层所用到的核心组件。我将为你介绍 Netty 的每个逻辑分层中的各个核心组件以及组件之间是如何协调运作的。 网络通信层 网络通信层的职责是执行网络 I/O 的操作。它支持多种网络协议和 I/O 模型的连接操作。当网络数据读取到内核缓冲区后，会触发各种网络事件，这些网络事件会分发给事件调度层进行处理。 BootStrap &amp;&amp; ServerBootStrap Bootstrap 是“引导”的意思，它主要负责整个 Netty 程序的启动、初始化、服务器连接等过程，它相当于一条主线，串联了 Netty 的其他核心组件。 如下图所示，Netty 中的引导器共分为两种类型：一个为用于客户端引导的 Bootstrap，另一个为用于服务端引导的 ServerBootStrap，它们都继承自抽象类 AbstractBootstrap。 Bootstrap 和 ServerBootStrap 十分相似，两者非常重要的区别在于 Bootstrap 可用于连接远端服务器，只绑定一个 EventLoopGroup。而 ServerBootStrap 则用于服务端启动绑定本地端口，会绑定两个 EventLoopGroup，这两个 EventLoopGroup 通常称为 Boss 和 Worker。 ServerBootStrap 中的 Boss 和 Worker 是什么角色呢？它们之间又是什么关系？这里的 Boss 和 Worker 可以理解为“老板”和“员工”的关系。每个服务器中都会有一个 Boss，也会有一群做事情的 Worker。Boss 会不停地接收新的连接，然后将连接分配给一个个 Worker 处理连接。 有了 Bootstrap 组件，我们可以更加方便地配置和启动 Netty 应用程序，它是整个 Netty 的入口，串接了 Netty 所有核心组件的初始化工作。 Channel Channel 的字面意思是“通道”，它是网络通信的载体。Channel提供了基本的 API 用于网络 I/O 操作，如 register、bind、connect、read、write、flush 等。Netty 自己实现的 Channel 是以 JDK NIO Channel 为基础的，相比较于 JDK NIO，Netty 的 Channel 提供了更高层次的抽象，同时屏蔽了底层 Socket 的复杂性，赋予了 Channel 更加强大的功能，你在使用 Netty 时基本不需要再与 Java Socket 类直接打交道。 下图是 Channel 家族的图谱。AbstractChannel 是整个家族的基类，派生出 AbstractNioChannel、AbstractOioChannel、AbstractEpollChannel 等子类，每一种都代表了不同的 I/O 模型和协议类型。常用的 Channel 实现类有： NioServerSocketChannel/EpollServerSocketChannel 都是异步TCP服务端； NioSocketChannel/EpollSocketChannel 都是异步TCP客户端 两者的区别是一个使用了select模型，一个使用了epoll 模型(这里不深入展开) 当然 Channel 会有多种状态，如连接建立、连接注册、数据读写、连接销毁等。随着状态的变化，Channel 处于不同的生命周期，每一种状态都会绑定相应的事件回调，下面的表格我列举了 Channel 最常见的状态所对应的事件回调。 事件 说明 channelRegistered Channel创建后被注册到EventLoop上 channelUnregistered Channel创建后未注册或者从EventLoop上取消 channelActive Channel处于就绪状态，可以被读写 channelInactive Channel 处于非就绪状态 channelRead Channel可以从远端读取到数据 channelReadComplete Channel读取数据完成 BootStrap 和 ServerBootStrap 分别负责客户端和服务端的启动，它们是非常强大的辅助工具类；Channel 是网络通信的载体，提供了与底层 Socket 交互的能力。那么 Channel 生命周期内的事件都是如何被处理的呢？那就是 Netty 事件调度层的工作职责了。 事件调度层 事件调度层的职责是通过 Reactor 线程模型对各类事件进行聚合处理，通过 Selector 主循环线程集成多种事件（ I/O 事件、信号事件、定时事件等），实际的业务处理逻辑是交由服务编排层中相关的 Handler 完成。 事件调度层的核心组件包括 EventLoopGroup、EventLoop。 EventLoopGroup &amp;&amp; EventLoop。 EventLoopGroup 本质是一个线程池，主要负责接收 I/O 请求，并分配线程执行处理请求。在下图中，我为你讲述了 EventLoopGroup、EventLoop 与 Channel 的关系。 一个 EventLoopGroup 往往包含一个或者多个 EventLoop。EventLoop 用于处理 Channel 生命周期内的所有 I/O 事件，如 accept、connect、read、write 等 I/O 事件。 EventLoop 同一时间会与一个线程绑定，每个 EventLoop 负责处理多个 Channel。 每新建一个 Channel，EventLoopGroup 会选择一个 EventLoop 与其绑定。该 Channel 在生命周期内都可以对 EventLoop 进行多次绑定和解绑。 下图是 EventLoopGroup 的家族图谱。可以看出 Netty 提供了 EventLoopGroup 的多种实现，而且 EventLoop 则是 EventLoopGroup 的子接口，所以也可以把 EventLoop 理解为 EventLoopGroup，但是它只包含一个 EventLoop 。 1234567891011/** * Will handle all the I/O operations for a {@link Channel} once registered. * * One {@link EventLoop} instance will usually handle more than one {@link Channel} but this may depend on * implementation details and internals. * */public interface EventLoop extends OrderedEventExecutor, EventLoopGroup { @Override EventLoopGroup parent();} EventLoopGroup 的实现类是 NioEventLoopGroup，NioEventLoopGroup 也是 Netty 中最被推荐使用的线程模型。NioEventLoopGroup 继承于 MultithreadEventLoopGroup，是基于 NIO 模型开发的，可以把 NioEventLoopGroup 理解为一个线程池，每个线程负责处理多个 Channel，而同一个 Channel 只会对应一个线程。 EventLoopGroup 是 Netty 的核心处理引擎，那么 EventLoopGroup 和之前提到的 Reactor 线程模型到底是什么关系呢？其实 EventLoopGroup 是 Netty Reactor 线程模型的具体实现方式，Netty 通过创建不同的 EventLoopGroup 参数配置，就可以支持 Reactor 的三种线程模型： 单线程模型：EventLoopGroup 只包含一个 EventLoop，Boss 和 Worker 使用同一个EventLoopGroup； 多线程模型：EventLoopGroup 包含多个 EventLoop，Boss 和 Worker 使用同一个EventLoopGroup； 主从多线程模型：EventLoopGroup 包含多个 EventLoop，Boss 是主 Reactor，Worker 是从 Reactor，它们分别使用不同的 EventLoopGroup，主 Reactor 负责新的网络连接 Channel 创建，然后把 Channel 注册到从 Reactor。 在介绍完事件调度层之后，可以说 Netty 的发动机已经转起来了，事件调度层负责监听网络连接和读写操作，然后触发各种类型的网络事件，需要一种机制管理这些错综复杂的事件，并有序地执行，接下来我们便一起学习 Netty 服务编排层中核心组件的职责。 服务编排层 服务编排层的职责是负责组装各类服务，它是 Netty 的核心处理链，用以实现网络事件的动态编排和有序传播。 服务编排层的核心组件包括 ChannelPipeline、ChannelHandler、ChannelHandlerContext。 ChannelPipeline ChannelPipeline 是 Netty 的核心编排组件，负责组装各种 ChannelHandler，实际数据的编解码以及加工处理操作都是由 ChannelHandler 完成的。ChannelPipeline 可以理解为ChannelHandler 的实例列表——内部通过双向链表将不同的 ChannelHandler 链接在一起。当 I/O 读写事件触发时，ChannelPipeline 会依次调用 ChannelHandler 列表对 Channel 的数据进行拦截和处理。 ChannelPipeline 是线程安全的，因为每一个新的 Channel 都会对应绑定一个新的 ChannelPipeline。一个 ChannelPipeline 关联一个 EventLoop，一个 EventLoop 仅会绑定一个线程。 C hannelPipeline大致结构流程 12345678910111213141516171819202122232425262728293031323334353637383940* &lt;pre&gt;* I/O Request* via {@link Channel} or* {@link ChannelHandlerContext}* |* +---------------------------------------------------+---------------+* | ChannelPipeline | |* | \\|/ |* | +---------------------+ +-----------+----------+ |* | | Inbound Handler N | | Outbound Handler 1 | |* | +----------+----------+ +-----------+----------+ |* | /|\\ | |* | | \\|/ |* | +----------+----------+ +-----------+----------+ |* | | Inbound Handler N-1 | | Outbound Handler 2 | |* | +----------+----------+ +-----------+----------+ |* | /|\\ . |* | . . |* | ChannelHandlerContext.fireIN_EVT() ChannelHandlerContext.OUT_EVT()|* | [ method call] [method call] |* | . . |* | . \\|/ |* | +----------+----------+ +-----------+----------+ |* | | Inbound Handler 2 | | Outbound Handler M-1 | |* | +----------+----------+ +-----------+----------+ |* | /|\\ | |* | | \\|/ |* | +----------+----------+ +-----------+----------+ |* | | Inbound Handler 1 | | Outbound Handler M | |* | +----------+----------+ +-----------+----------+ |* | /|\\ | |* +---------------+-----------------------------------+---------------+* | \\|/* +---------------+-----------------------------------+---------------+* | | | |* | [ Socket.read() ] [ Socket.write() ] |* | |* | Netty Internal I/O Threads (Transport Implementation) |* +-------------------------------------------------------------------+* &lt;/pre&gt; 从上图可以看出，ChannelPipeline 中包含入站 ChannelInboundHandler 和出站 ChannelOutboundHandler 两种处理器，我们结合客户端和服务端的数据收发流程来理解 Netty 的这两个概念。 客户端和服务端都有各自的 ChannelPipeline。以客户端为例，数据从客户端发向服务端，该过程称为出站，反之则称为入站。数据入站会由一系列 InBoundHandler 处理，然后再以相反方向的 OutBoundHandler 处理后完成出站。我们经常使用的编码 Encoder 是出站操作，解码 Decoder 是入站操作。服务端接收到客户端数据后，需要先经过 Decoder 入站处理后，再通过 Encoder 出站通知客户端。所以客户端和服务端一次完整的请求应答过程可以分为三个步骤：客户端出站（请求数据）、服务端入站（解析数据并执行业务逻辑）、服务端出站（响应结果）。 ChannelHandler &amp;&amp; ChannelHandlerContext 下图描述了 Channel 与 ChannelPipeline 的关系，从图中可以看出，每创建一个 Channel 都会绑定一个新的 ChannelPipeline，ChannelPipeline 中每加入一个 ChannelHandler 都会绑定一个 ChannelHandlerContext。由此可见，ChannelPipeline、ChannelHandlerContext、ChannelHandler 三个组件的关系是密切相关的 ChannelHandlerContext 用于保存 ChannelHandler 上下文，通过 ChannelHandlerContext 我们可以知道 ChannelPipeline 和 ChannelHandler 的关联关系。ChannelHandlerContext 可以实现 ChannelHandler 之间的交互，ChannelHandlerContext 包含了 ChannelHandler 生命周期的所有事件，如 connect、bind、read、flush、write、close 等。此外，你可以试想这样一个场景，如果每个 ChannelHandler 都有一些通用的逻辑需要实现，没有 ChannelHandlerContext 这层模型抽象，你是不是需要写很多相同的代码呢？ 1234567public interface ChannelHandlerContext extends AttributeMap, ChannelInboundInvoker, ChannelOutboundInvoker { /** * Return the {@link Channel} which is bound to the {@link ChannelHandlerContext}. */ Channel channel(); ... 以上便是 Netty 的逻辑处理架构，可以看出 Netty 的架构分层设计得非常合理，屏蔽了底层 NIO 以及框架层的实现细节，对于业务开发者来说，只需要关注业务逻辑的编排和实现即可。 组件关系梳理 服务端启动初始化时有 Boss EventLoopGroup 和 Worker EventLoopGroup 两个组件，其中 Boss 负责监听网络连接事件。当有新的网络连接事件到达时，则将 Channel 注册到 Worker EventLoopGroup。 Worker EventLoopGroup 会分配一个 EventLoop 负责处理该 Channel 的读写事件。每个 EventLoop 都是单线程的，通过 Selector 进行事件循环。 当客户端发起 I/O 读写事件时，服务端 EventLoop 会进行数据的读取，然后通过 Pipeline 触发各种监听器进行数据的加工处理。 客户端数据会被传递到 ChannelPipeline 的第一个 ChannelInboundHandler 中，数据处理完成后，将加工完成的数据传递给下一个 ChannelInboundHandler。 当数据写回客户端时，会将处理结果在 ChannelPipeline 的 ChannelOutboundHandler 中传播，最后到达客户端。 Netty 源码结构 Netty 源码分为多个模块，模块之间职责划分非常清楚。如同上文整体功能模块一样，Netty 源码模块的划分也是基本契合的。 我们不仅可以使用 Netty all-in-one 的 Jar 包，也可以单独使用其中某些工具包。下面我根据 Netty 的分层结构以及实际的业务场景具体介绍 Netty 中常用的工具包。 Core核心层模块 netty-common模块是 Netty 的核心基础包，提供了丰富的工具类，其他模块都需要依赖它。在 common 模块中，常用的包括通用工具类和自定义并发包 通用工具类：比如定时器工具 TimerTask、时间轮 HashedWheelTimer 等。 自定义并发包：比如异步模型Future &amp; Promise、相比 JDK 增强的 FastThreadLocal 等。 在netty-buffer 模块中Netty自己实现了的一个更加完备的ByteBuf 工具类，用于网络通信中的数据载体。由于人性化的 Buffer API 设计，它已经成为 Java ByteBuffer 的完美替代品。ByteBuf 的动态性设计不仅解决了 ByteBuffer 长度固定造成的内存浪费问题，而且更安全地更改了 Buffer 的容量。此外 Netty 针对 ByteBuf 做了很多优化，例如缓存池化、减少数据拷贝的 CompositeByteBuf 等。 netty-resover模块主要提供了一些有关基础设施的解析工具，包括IP Address，HostName,DNS等。 Protocol Support 协议支持层膜哦快 netty-codec模块主要负责编解码工作，通过编解码实现原始字节数据业务实体对象之间的相互转化。如下图所示，Netty 支持了大多数业界主流协议的编解码器，如 HTTP、HTTP2、Redis、XML 等，为开发者节省了大量的精力。此外该模块提供了抽象的编解码类 ByteToMessageDecoder 和 MessageToByteEncoder，通过继承这两个类我们可以轻松实现自定义的编解码逻辑。 netty-handler模块主要负责数据处理工作。Netty 中关于数据处理的部分，本质上是一串有序 handler 的集合。netty-handler 模块提供了开箱即用的 ChannelHandler 实现类，例如日志、IP 过滤、流量整形等，如果你需要这些功能，仅需在 pipeline 中加入相应的 ChannelHandler 即可。 Transport Service 传输服务层模块 netty-transport 模块可以说是 Netty 提供数据处理和传输的核心模块。该模块提供了很多非常重要的接口，如 Bootstrap、Channel、ChannelHandler、EventLoop、EventLoopGroup、ChannelPipeline 等。其中 Bootstrap 负责客户端或服务端的启动工作，包括创建、初始化 Channel 等；EventLoop 负责向注册的 Channel 发起 I/O 读写操作；ChannelPipeline 负责 ChannelHandler 的有序编排，这些组件在介绍 Netty 逻辑架构的时候都有所涉及。","link":"/netty/Netty%E7%9A%84%E6%95%B4%E4%BD%93%E6%9E%B6%E6%9E%84%E8%84%89%E7%BB%9C.html"},{"title":"JVM 卷","text":"JVM 内存区域 这张图就是一个 JVM 运行时数据图，「紫色区域代表是线程共享的区域」，JAVA 程序在运行的过程中会把他管理的内存划分为若干个不同的数据区域，「每一块的数据区域所负责的功能都是不同的，他们也有不同的创建时间和销毁时间」 程序计数器： 是「程序控制流的指示器，循环，跳转，异常处理，线程的恢复等工作都需要依赖程序计数器去完成」。程序计数器是「线程私有」的，它的「生命周期是和线程保持一致」的，我们知道，N 个核心数的 CPU 在同一时刻，最多有 N个线程同时运行，在我们真实的使用过程中可能会创建很多线程，JVM 的多线程其实是通过线程轮流切换，分配处理器执行时间来实现的。既然涉及的线程切换，所以每条线程必须有一个独立的程序计数器; 虚拟机栈：其描述的就是线程内存模型，「也可以称作线程栈」，也是每个「线程私有」的，「生命周期与线程保持一致」。在每个方法执行的时候，jvm 都会同步创建一个栈帧去存储局部变量表，操作数栈，动态连接，方法出口等信息。一个方法的生命周期就贯彻了一个栈帧从入栈到出栈的全部过程; 本地方法栈：java底层用了很多c的代码去实现，而其调用c端的方法上都会有native，代表本地方法服务，而本地方法栈就是为其服务的； 堆：堆可以说是jvm中最大的一块儿内存区域了，它是所有线程共享的，不管你是初学者还是资深开发，多少都会听说过堆，毕竟几乎所有的对象都会在堆中分配； 方法区：也是所有「线程共享」的区域，它「存储」了被 jvm 加载的类型信息、常量、静态变量等数据。运行时常量池就是方法区的一部分，编译期生成的各种字面量与符号引用就存储在其中; 直接内存:这部分数据并「不是 jvm 运行时数据区的一部分」，nio 就会使用到直接内存，也可以说「堆外内存」，通常会「配合虚引用一起去使用」，就是为了资源释放，会将堆外内存开辟空间的信息存储到一个队列中，然后GC会去清理这部分空间。堆外内存优势在 IO 操作上，对于网络 IO，使用 Socket 发送数据时，能够节省堆内存到堆外内存的数据拷贝，所以性能更高。Netty 使用堆外内存池来实现零拷贝技术。对于磁盘 IO 时，也可以使用内存映射，来提升性能。另外，更重要的几乎不用考虑堆内存烦人的 GC 问题。但是既然是内存。也会受到本机总内存的限制 首先通过编译器把 Java源代码转换成字节码，Class loader(类装载)再把字节码加载到内存中，将其放在运行时数据区的方法区内，而字节码文件只是 JVM 的一套指令集规范，并不能直接交给底层操作系统去执行，因此需要特定的命令解析器执行引擎（Execution Engine），将字节码翻译成底层系统指令，再交由 CPU 去执行，而这个过程中需要调用其他语言的本地库接口（Native Interface）来实现整个程序的功能。 垃圾对象是怎么找到的？引用计数法就是给对象添加一个计数器 每当有一个地方引用它的时候，计数器就加1 每当有一个引用失效的时候，计数器就减1 当计数器的值为0的时候，那么该对象就是垃圾了。这种方案的原理很简单，而且判定的效率也非常高，但是却可能会有其他的额外情况需要考虑 比如两个对象循环引用，a 对象引用了 b 对象，b 对象也引用了 a 对象，a、b 对象却没有再被其他对象所引用了，其实正常来说这两个对象已经是垃圾了，因为没有其他对象在使用了，但是计数器内的数值却不是 0，所以引用计数算法就无法回收它们。这种算法是比较直接的找到垃圾，然后去回收，也被称为”直接垃圾收集”。 根可达算法这也是JVM 默认使用的寻找垃圾算法它的原理就是定义了一系列的根，我们把它称为 GC Roots ，从 GC Roots 开始往下进行搜索，走过的路径我们把它称为 引用链 ，当一个对象到 GC Roots 之间没有任何引用链相连时，那么这个对象就可以被当做垃圾回收了。 如图，根可达算法就可以避免计数器算法不好解决的循环引用问题，Object 6、Object 7、Object 8彼此之前有引用关系，但是没有与GC Roots 相连，那么就会被当做垃圾所回收。 GC Roots 有哪些在java中，有固定的GC Roots对象和不固定的临时GC Roots对象 固定的GC Roots对象 在虚拟机栈(栈帧的本地变量表)中所引用的对象，譬如各个线程被调用的方法堆栈中使用到的参数、局部变量、临时变量等; 在方法区中类静态属性引用的对象，譬如 Java 类的引用静态变量; 在方法区中常量引用的对象，譬如字符串常量池中的引用; 在方法区栈中 JNI (譬如 Native 方法)引用的对象 Java 虚拟机内部的引用，如基本数据类型对应的 Class 对象，一些常驻的异常对象(空指针异常、OOM等)，还有类加载器 所有被 Synchronized 持有的对象 反应 Java 虚拟机内部情况的 JMXBean、JVMTI 中注册的回调本地代码缓存等 不固定的临时GC Roots对象 目前的垃圾回收大部分都是分代收集和局部回收，如果只针对某一部分区域进行局部回收，那么就必须要考虑的当前区域的对象有可能正被其他区域的对象所引用，这时候就要将这部分关联的对象也添加到 GC Roots 中去来确保根可达算法的准确性。这种算法是利用了逆向思维，找到使用的对象，剩下的就是垃圾，也被称为”间接垃圾收集”。 Java 有哪四种引用类型强引用 Object o = new Object 就是一种强引用的关系，无论任何情况下，只要强引用关系还存在，垃圾回收器就不会回收掉被引用的对象 软引用 当内存空间不足时，就会回收软引用对象； 软引用用来描述那些有用但是没必要的对象。 1SoftReference sr = new SoftReference(str); 弱引用 弱引用要比软引用更弱一些，它 只能够存活到下次垃圾回收之前。也就是说，垃圾回收器开始工作，回收掉所有只被弱引用关联的对象. 在ThreadLocal中就使用了弱引用来防止内存泄漏。 1WeekReference wr = new WeekReference(str); 虚引用 虚引用是最弱的一种引用关系，它的唯一作用是用来作为一种通知。如零拷贝(Zero Copy)，开辟了堆外内存，虚引用在这里使用，会将这部分信息存储到一个队列中，以便于后续对堆外内存的回收管理. 分代收集理论大多数的垃圾回收器都遵循了分代收集的理论进行设计，它建立在两个分代假说之上: 弱分代假说：绝大多数对象都是朝生夕灭的； 强分代假说：熬过越多次垃圾回收过程的对象就越难消亡； 这两种假说的设计原则都是相同的:垃圾收集器应该将jvm划分出不同的区域，把那些较难回收的对象放在一起（一般指老年代），这个区域的垃圾回收频率就可以降低，减少垃圾回收的开销。剩下的区域(一般指新生代)可以用较高的频率去回收，并且只需要去关心那些存活的对象，也不用标记出需要回收的垃圾，这样就能够以较低的代价去完成垃圾回收. 跨代引用假说：如果某个新生代的对象存在了跨代引用，但是老年代的对象是很难消亡的，那么随着时间的推移，这个新生代对象也会慢慢晋升为老年代对象，那么这种跨代引用也就被消除了 由于跨代引用是很少的，所以我们不应该为了少量的跨代引用去扫描整个老年代的数据，只需要在新生代对象建立一个记忆集来记录引用信息。记忆集:将老年代分为若干个小块，每块区域中有 N 个对象，在对象引用信息发生变动的时候来维护记忆集数据的准确性，这样每次发生了 “Minor GC” 的时候只需要将记忆集中的对象添加到 **”GC Roots”**中就可以了 垃圾收集算法有哪些标记清除算法这种算法的实现是很简单的，有两种方式 标记出垃圾，然后清理掉； 标记出存活的对象，回收其他的空间。 这种算法有两个缺点： 随着对象越来越多，那么所需要消耗的时间就会越来越多； 标记清除后会导致碎片化，如果有大对象分配很有可能分配不下而出发另一次的垃圾收集动作 标记复制算法 这种算法解决了第一种算法碎片化的问题。就是开辟两块完全相同的区域，对象只在其中一篇区域内分配，然后标记出那些存活的对象，按顺序整体移到另外一个空间，如下图，可以看到回收后的对象是排列有序的，这种操作只需要移动指针就可以完成，效率很高，之后就回收移除前的空间。 这种算法的缺点也是很明显的 浪费过多的内存，使现有的可用空间变为原先的一半; 标记整理算法这种算法可以说是结合了前两种算法，既有标记删除，又有整理功能。 这种算法就是通过标记清除算法找到存活的对象，然后将所有存活的对象，向空间的一端移动，然后回收掉其他的内存。 什么是STW Java 中Stop-The-World机制简称 STW ，是在执行垃圾收集算法时，Java 应用程序的其他所有线程都被挂起（除了垃圾收集帮助器之外）。Java 中一种全局暂停现象，全局停顿，所有 Java 代码停止，native 代码可以执行，但不能与 JVM 交互。 为什么需要STW 在 java 应用程序中引用关系是不断发生变化的，那么就会有会有很多种情况来导致垃圾标识出错。想想一下如果 Object a 目前是个垃圾，GC 把它标记为垃圾，但是在清除前又有其他对象指向了 Object a，那么此刻 Object a 又不是垃圾了，那么如果没有 STW 就要去无限维护这种关系来去采集正确的信息。 垃圾回收器是怎样寻找 GC Roots 的？ 我们在前面说明了根可达算法是通过 GC Roots 来找到存活的对象的，也定义了 GC Roots，那么垃圾回收器是怎样寻找GC Roots 的呢？首先，为了保证结果的准确性，GC Roots枚举时是要在STW的情况下进行的，但是由于 JAVA 应用越来越大，所以也不能逐个检查每个对象是否为 GC Root，那将消耗大量的时间。一个很自然的想法是，能不能用空间换时间，在某个时候把栈上代表引用的位置全部记录下来，这样到真正 GC 的时候就可以直接读取，而不用再一点一点的扫描了。事实上，大部分主流的虚拟机也正是这么做的，比如 HotSpot ，它使用一种叫做 OopMap 的数据结构来记录这类信息 OopMap是做什么的？有什么好处？ 我们知道，一个线程意味着一个栈，一个栈由多个栈帧组成，一个栈帧对应着一个方法，一个方法里面可能有多个安全点。gc 发生时，程序首先运行到最近的一个安全点停下来，然后更新自己的 OopMap ，记下栈上哪些位置代表着引用。枚举根节点时，递归遍历每个栈帧的 OopMap ，通过栈中记录的被引用对象的内存地址，即可找到这些对象（ GC Roots ）。使用 OopMap 可以避免全栈扫描，加快枚举根节点的速度。但这并不是它的全部用意。它的另外一个更根本的作用是，可以帮助 HotSpot 实现准确式 GC (即使用准确式内存管理，虚拟机可用知道内存中某个位置的数据具体是什么类型) 。 什么是安全点？ 从线程角度看，安全点可以理解成是在代码执行过程中的一些特殊位置，当线程执行到这些位置的时候，说明虚拟机当前的状态是安全的。比如：方法调用、循环跳转、异常跳转等这些地方才会产生安全点。如果有需要，可以在这个位置暂停，比如发生GC时，需要暂停所有活动线程，但是线程在这个时刻，还没有执行到一个安全点，所以该线程应该继续执行，到达下一个安全点的时候暂停，等待 GC 结束。那么如何让线程在垃圾回收的时候都跑到最近的安全点呢？这里有两种方式： 抢先式中断：就是在stw的时候，先让所有线程完全中断，如果中断的地方不在安全点上，然后再激活，直到运行到安全点的位置再中断。 主动式中断：在安全点的位置打一个标志位，每个线程执行都去轮询这个标志位，如果为真，就在最近的安全点挂起 安全区域是什么?解决了什么问题 刚刚说到了主动式中断,但是如果有些线程处于sleep状态怎么办呢？ 为了解决这种问题，又引入了安全区域的概念安全区域是指在一段代码片中，引用关系不会发生改变，实际上就是一个安全点的拓展。当线程执行到安全区域时，首先标识自己已进入安全区域，那样，当在这段时间里 JVM 要发起 GC 时，就不用管标识自己为“安全区域”状态的线程了，该线程只能乖乖的等待根节点枚举完或者整个GC过程完成之后才能继续执行。 垃圾回收器了解吗？年轻代和老年代都有哪些垃圾回收器？ Serial：单线程版本收集器，进行垃圾回收的时候会 STW（Stop The World），也就是进行垃圾回收的时候其他的工作线程都必须暂停。可以与 CMS 垃圾回收器一起搭配工作。 ParNew：Serial 的多线程版本，用于和 CMS 配合使用 Parallel Scavenge：可以并行收集的多线程垃圾收集器。采用复制算法负责新生代 是与 ParNew 类似，都是用于年轻代回收的使用复制算法的并行收集器，与 ParNew 不同的是，Parallel Scavenge 的目标是达到一个可控的吞吐量。吞吐量=程序运行时间/（程序运行时间+GC时间）。如程序运行了99s，GC耗时1s，吞吐量=99/（99+1）=99%。Parallel Scavenge 提供了两个参数用以精确控制吞吐量，分别是用以控制最大 GC 停顿时间的 -XX:MaxGCPauseMillis 及直接控制吞吐量的参数 -XX:GCTimeRatio.停顿时间越短就越适合需要与用户交互的程序，良好的响应速度能提升用户体验，而高吞吐量则可以高效的利用 CPU 时间，尽快完成程序的运算任务，主要适合在后台运算而不需要太多交互的任务。 Serial Old：Serial 的老年代版本，也是单线程。 Parallel Old：Parallel Scavenge 的老年代版本,可以与 Parallel Scavenge 垃圾回收器一起搭配工作 Parallel Old 是 Pararllel Scavenge 的老年代版本，它的设计思路也是以吞吐量优先的，ps+po 是很常用的一种组合。 CMSCMS（Concurrent Mark Sweep）：CMS 收集器是以获取最短停顿时间为目标的收集器。相对于其他的收集器 STW 的时间更短暂，可以并行收集是它的特点，同时它基于标记-清除算法。 初始标记：标记 GC ROOT 能关联到的对象，整个速度是非常快的，为了保证标记的准确，需要 STW； 并发标记：从 GCRoots 的直接关联对象开始遍历整个对象图的过程，这一部分时刻用户线程并发运行的，虽然耗时较长，但是不会有很大的影响，不需要 STW； 重新标记：为了修正并发标记期间，因用户程序继续运作而导致标记产生改变的标记，这里简单举个例子：并发标记时a没有被任何对象引用，此时垃圾回收器将该对象标位垃圾，在之后的标记过程中，a又被其他对象引用了，这时候如果不进行重新标记就会发生误清除，需要 STW； 并发清除：清理删除掉标记阶段判断的已经死亡的对象，这部分会和用户线程一起并发执行。不需要 STW CMS的三个缺点 影响用户线程的执行效率 CMS默认启动的回收线程数是（处理器核心数 + 3）/ 4 ,由于是和用户线程一起并发清理，那么势必会影响到用户线程的执行速度，并且这个影响随着核心线程数的递减而增加。所以 JVM 提供了一种 “增量式并发收集器“的 CMS 变种，主要是用来减少垃圾回收线程独占资源的时间，所以会感觉到回收时间变长，这样的话单位时间内处理垃圾的效率就会降低」也是一种缓和的方案。 会产生”浮动垃圾 之前说到 CMS 真正清理垃圾是和用户线程一起进行的，在清理这部分垃圾的时候用户线程会产生新的垃圾，这部分垃圾就叫做浮动垃圾，并且只能等着下一次的垃圾回收再清除 会产生碎片化的空间 CMS 是使用了标记删除的算法去清理垃圾的，而这种算法的缺点就是会产生碎片化，后续可能会导致大对象无法分配从而触发和 Serial Old 一起配合使用来处理碎片化的问题，当然这也处于 STW的情况下，所以当 java 应用非常庞大时，如果采用了 CMS 垃圾回收器，产生了碎片化，那么在 STW 来处理碎片化的时间会非常之久 G1 G1 垃圾回收器把堆划分成一个个大小相同的Region，每个 Region 都会扮演一个角色，H、S、E、O。E代表伊甸区，S代表 Survivor 区，H代表的是 Humongous(G1用来分配大对象的区域，对于 Humongous 也分配不下的超大对象，会分配在连续的 N 个 Humongous 中)，剩余的深蓝色代表的是 Old 区，白色的代表的是空闲的 region。在 HotSpot 的实现中，整个堆被划分成2048左右个 Region。每个 Region 的大小可以通过 -XX：G1HeapRegionSize 设置，大小为1~32M。，具体多大取决于堆的大小。在并发标记垃圾时也会产生新的对象，G1 对于这部分对象的处理是这样的：将 Region 新增一块并发回收过程中分配对象的空间，并为此设计了两个 TAMS(Top at Mark Start)指针，这块区域专门用来在并发时分配新对象，有对象新增只需要将 TAMS 指针移动下就可以了，并且这些新对象默认是标记为存活，这样就不会干扰到标记过程 但是这种方法也会有个问题，有可能垃圾回收的速度小于新对象分配的速度，这样会导致 “Full GC” 而产生长时间的 STW。在 G1 的设计理念里，最小回收单元是 Region，每次回收的空间大小都是Region的N倍，那么G1是怎么选择要回收哪块儿区域的呢？G1 会跟踪各个 Region 区域内的垃圾价值，和回收空间大小回收时间有关，然后维护一个优先级列表，来收集那些价值最高的Reigon区域。 G1 的回收过程分为以下四个步骤： 初始标记：标记 GC ROOT 能关联到的对象，修改 TAMS 的值以便于并发回收时新对象分配,需要 STW； 并发标记：从 GCRoots 的直接关联对象开始遍历整个对象图的过程，扫描完成后还会重新处理并发标记过程中产生变动的对象，记录 SATB(原始快照) 在并发时有引用的值； 最终标记：短暂暂停用户线程，再处理一次，处理第二步遗留下来的少量 SATB(原始快照) 记录，需要 STW； 筛选回收：更新 Region 的统计数据，对每个 Region 的回收价值和成本排序，根据用户设置的停顿时间制定回收计划。再把需要回收的 Region 中存活对象复制到空的 Region，同时清理旧的 Region。需要 STW。 说说三色标记 垃圾回收器标记垃圾的时候使用的算法 ,将对象分成三种颜色 白色：没被GC访问过的对象（被 GC 标记完后还是白色代表是垃圾） 黑色：存活的对象 灰色：被GC访问过的对象，但是对象引用链上至少还有一个引用没被扫描过 在并发标记的时候可能会出现误标的情况 刚开始标记为垃圾的对象，但是在并发标记过程中变为了存活对象 刚开始标记为存活的对象，但是在并发标记过程中变为了垃圾对象 第一种情况影响还不算很大，只是相当于垃圾没有清理干净，待下一次清理的时候再清理一下就好了。第二种情况就危险了，正在使 用的对象的突然被清理掉 了，后果会很严重。那么 产生上述第二种情况的原因 是什么呢？ 新增 一条或多条 黑色到白色 对象的新引用 删除 了 灰色 对象 到该白色对象 的直接 引用或间接引用。 当这两种情况 都满足 的时候就会出现这种问题了。所以为了解决这个问题，引入了 增量更新 (Incremental Update)和 原始快照 (SATB)的方案： 增量更新破坏了第一个条件：增加新引用时记录 该引用信息，在后续 STW 扫描中重新扫描(CMS的使用方案)。 原始快照破坏了第二个条件：删除引用时记录下来，在后续 STW 扫描时将这些记录过的灰色对象为根再扫描一次(G1的使用方案)。 什么情况下会发生栈内存溢出？Java 栈内存溢出可能抛出两种异常，两种异常虽然都发生在栈内存，但是两者导致内存溢出的根本原因是不一样的： 如果线程请求分配的栈容量超过 Java 虚拟机栈允许的最大容量的时候，Java 虚拟机将抛出一个 StackOverFlowError 异常。 如果 Java 虚拟机栈可以动态拓展，并且扩展的动作已经尝试过，但是目前无法申请到足够的内存去完成拓展，或者在建立新线程的时候没有足够的内存去创建对应的虚拟机栈，那 Java 虚拟机将会抛出一个 OutOfMemoryError 异常。 如何排查 OOM 的问题？ 增加两个参数 -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/tmp/heapdump.hprof，当 OOM 发生时自动 dump 堆内存信息到指定目录； 2.同时 jstat 查看监控 JVM 的内存和 GC 情况，先观察问题大概出在什么区域； 3.使用工具载入到 dump 文件，分析大对象的占用情况。 说一说类加载机制是什么?加载的过程又是怎么样的？介绍一下双亲委派模型,它的好处是什么 类加载机制 Java 虚拟机把描述类的数据从 Class 文件加载到内存，并对数据进行校验、转换解析和初始化，最终形成可以被 Jvm 可以直接使用的类型，这个过程就可以成为虚拟机的类加载机制。 类加载过程加载 将class文件加载至java虚拟机，并存储在方法区。方法区存储类信息、常量、静态变量 连接-验证 确保加载进来的class文件包含的信息是否符合java虚拟机的要求。是否合法、是否安全。验证项目包括：文件格式验证、元数据验证、字节码验证、符号引用验证。 连接-准备 为类变量分配内存，并设置类变量的初始值。 进行内存分配的包括类变量(static 修饰的变量),而不包括实例变量，实例变量将会在对象实例化时随着对象一起分配在java堆中。 其次是这里所说的初始值“通常情况”下是数据类型的零值（如0、0L、null、false等）。 连接-解析 将变量池里符号引用转为直接引用 初始化 初始化类变量、静态语句块。 在以下四种情况下初始化过程会被触发执行： 遇到new、getstatic、putstatic或invokestatic这4条字节码指令时，如果类没有进行过初始化，则需先触发其初始化； 使用java.lang.reflect包的方法对类进行反射调用的时候； 当初始化一个类的时候，如果发现其父类还没有进行过初始化、则需要先出发其父类的初始化； jvm启动时，用户指定一个执行的主类(包含main方法的那个类)，虚拟机会先初始化这个类 使用 使用类 卸载 执行了System.exit()方法 程序正常执行结束 程序在执行过程中遇到了异常或错误而异常终止 由于操作系统出现错误而导致Java虚拟机进程终止 真实情况是加载、验证、准备、初始化、卸载这五个阶段的顺序是确定的，是依次有序的。但是解析阶段有可能会在初始化之后才会进行，这是为了支持 Java 动态绑定的特性 动态绑定: 在运行时根据具体对象的类型进行绑定。提供了一些机制，可在运行期间判断对象的类型，并分别调用适当的方法。也就是说，编译器此时依然不知道对象的类型，但方法调用机制能自己去调查，找到正确的方法主体。 双亲委派模型 简而言之，就是说一个类加载器收到了类加载的请求，不会自己先加载，而是把它交给自己的父类去加载，层层迭代。 用上图来说明就是如果应用程序类加载器收到了一个类加载的请求，会先给扩展类加载器，然后再给启动类加载器，如果启动类加载器无法完成这个类加载的请求，再返回给扩展类加载器，如果扩展类加载器也无法完成，就返回给应用类加载器。 说一说对象的栈上分配吧 如果所有对象都分配在堆中那么会给 GC 带来许多不必要的压力,比如有些对象的生命周期只是在当前线程中，为了减少临时对象在堆内分配的数量，就可以在在栈上分配，随着线程的消亡而消亡。当然栈上空间必须充足,否则也无法分配，在判断是否能分配到栈上的另一条件就是要经过逃逸分析， 逃逸分析(Escape Analysis) 简单来讲就是：Java Hotspot 虚拟机判断这个新对象是否只会被当前线程引用，并且决定是否能够在 Java 堆上分配内存。 对象的内存布局是怎样的? 对象头: 对象头又分为 MarkWord 和 Class Pointer 两部分。 MarkWord:包含一系列的标记位，比如轻量级锁的标记位，偏向锁标记位,gc记录信息等等。 ClassPointer:用来指向对象对应的 Class 对象（其对应的元数据对象）的内存地址。在 32 位系统占 4 字节，在 64 位系统中占 8 字节。 Length:只在数组对象中存在，用来记录数组的长度，占用 4 字节 Instance data: 对象实际数据，对象实际数据包括了对象的所有成员变量，其大小由各个成员变量的大小决定。(这里不包括静态成员变量，因为其是在方法区维护的) Padding:Java 对象占用空间是 8 字节对齐的，即所有 Java 对象占用 bytes 数必须是 8 的倍数,是因为当我们从磁盘中取一个数据时，不会说我想取一个字节就是一个字节，都是按照一块儿一块儿来取的，这一块大小是 8 个字节，所以为了完整，padding 的作用就是补充字节，「保证对象是 8 字节的整数倍」。","link":"/%E5%85%AB%E8%82%A1%E6%96%87/JVM-%E5%8D%B7.html"},{"title":"mysql日志系统","text":"MySQL日志 说起MySQL的日志，有三种类型的日志对于MySQL来说是至关重要的，这三种日志分别为：Binlog、Undo Log 和 Redo Log。 Undo Log 日志 顾名思义，Undo Log的字面意思就是撤销操作的日志，指的是使MySQL中的数据回到某个状态。 Undo Log是一种 逻辑日志， 记录的是一个变化过程。比如，MySQL执行一个delete操作，Undo Log就会记录一个insert操作；MySQL执行一个insert操作，Undo Log就会记录一个delete操作；MySQL执行一个update操作，Undo Log就会记录一个相反的update操作。 Undo Log以段的方式来管理和记录日志信息，在InnoDB存储引擎的数据文件中，包含了一种叫做rollback segment的回滚段，其内部包含了1024个undo log senment。 作用 Undo Log对于MySQL实现事务来说，起着至关重要的作用，它实现了事务的原子性和多版本并发控制，也就是我们经常说的MVCC。 实现事务的原子性 Undo Log能够实现MySQL事务的原子性，在事务的处理过程中，如果MySQL出现了错误或者用户手动执行了事务的回滚操作（执行了rollback操作），MySQL可以利用Undo Log日志将数据库中的数据恢复到之前的状态。 实现MVCC机制 事务未提交前，Undo Log保存了未提交之前的版本数据，Undo Log中的数据可以作为旧版本数据的副本或者快照以便其他并发事务进行读取操作。 事务A手动开启事务后，对goods数据表中id为1的数据进行更新操作，首先会把更新命中的数据写入到Undo Buffer中。 在事务A未提交之前，此时，事务B手动开启事务，对goods数据表中的id为1的数据进行查询操作，此时的事务B会读取Undo Log中的数据并返回给客户端，这就是MySQL中的MVCC机制。 可以在MySQL中通过下面的命令来查看控制Undo Log日志的参数 1show variables like '%innodb_undo%'; Redo Log日志 Redo Log的字面意思就是重做日志，指的是在数据库出现意外情况时能够对重新执行某种操作。在MySQL中，事务中修改的任何数据，都会将最新的数据写入Redo Log中进行备份 在MySQL中，随着事务操作的执行，就会产生Redo Log日志，在事务提交时会产生Redo Log并将其写入Redo Buffer，Redo Buffer也并不是随着事务的提交就会被立刻写入到磁盘中，而是等事务操作的脏页写入到磁盘之后，Redo Log的使命也就完成了，此时，Redo Log日志占用的空间可以重新利用，会被后续产生的Redo Log日志覆盖 Redo Log 的原理 Redo Log 能够实现事务的持久性，防止在发生故障的时间点，有脏页未写入表的 ibd 文件中，在重启 MySQL 服务的时候，根据 Redo Log 进行重做，从而将未提交的事务进行持久化。这个过程可以简化为下图所示。 Redo Log 的写机制Redo Log文件的内容是以顺序循环的方式写入文件的，写满时就会回到第一个文件，进行覆盖写。 Write Pos 是当前记录的位置，一边写一边后移，写到最后一个文件末尾后就回到 0 号文件开头； CheckPoint是当前要擦除的位置，也是往后推移并且循环的，擦除记录前要把记录更新到数 据文件； Write Pos 和 CheckPoint之间还空着的部分，可以用来记录新的操作。如果 Write Pos 追上 CheckPoint，表示已经写满，此时就需要向后移动CheckPoint来擦除数据。 每个InnoDB存储引擎至少有1个重做日志文件组（group），每个文件组至少有2个重做日志文件，默认为ib_logfile0和ib_logfile1 。 可以在MySQL中通过如下命令来查看控制Redo Log的参数。 1show variables like '%innodb_log%'; Redo Log 写入机制 在Redo Log日志信息从Redo Buffer持久化到Redo Log时，具体的持久化策略可以通过innodb_flush_log_at_trx_commit 参数进行设置，具体策略如下所示。 0：每秒提交 Redo buffer -&gt;OS cache -&gt; flush cache to disk，可能丢失一秒内的事务数据。由后台Master线程每隔 1秒执行一次操作。 1（默认值）：每次事务提交执行 Redo Buffer -&gt; OS cache -&gt; flush cache to disk，这种方式最安全，性能最差。 2：每次事务提交执行 Redo Buffer -&gt; OS cache，然后由后台Master线程再每隔1秒执行OS cache -&gt; flush cache to disk 的操作。 一般建议选择取值2，因为 MySQL 挂了数据没有损失，整个服务器挂了才会损失1秒的事务提交数据。 Binlog 日志 Binlog记录所有MySQL数据库表结构变更以及表数据修改的二进制日志，不会记录select和show这类查询操作的日志。Binlog日志是以事件形式记录，还包含语句所执行的消耗时间。开启Binlog日志有以下两个最重要的使用场景。 主从复制：在主库中开启Binlog功能，这样主库就可以把Binlog传递给从库，从库拿到Binlog后实现数据恢复达到主从数据一致性。 数据恢复：通过mysqlbinlog等工具来恢复数据 Binlog 文件记录模式 Binlog文件记录模式有STATEMENT、ROW和MIXED三种， ROW 模式 ROW（row-based replication, RBR）：日志中会记录每一行数据被修改的情况，然后在slave端对相同的数据进行修改。 优点：能清楚记录每一个行数据的修改细节，能完全实现主从数据同步和数据的恢复。 缺点：批量操作，会产生大量的日志，尤其是alter table会让日志暴涨 STATMENT 模式 STATMENT（statement-based replication, SBR）：每一条被修改数据的SQL都会记录到master的Binlog中，slave在复制的时候SQL进程会解析成和原来master端执行过的相同的SQL再次执行。简称SQL语句复制。 优点：日志量小，减少磁盘IO，提升存储和恢复速度 缺点：在某些情况下会导致主从数据不一致，比如last_insert_id()、now()等函数。 MIXED模式 MIXED（mixed-based replication, MBR）：以上两种模式的混合使用，一般会使用STATEMENT模式保存binlog，对于STATEMENT模式无法复制的操作使用ROW模式保存binlog，MySQL会根据执行的SQL语句选择写入模式 。 Bingo 写机制 根据记录模式和操作触发event事件生成log event（事件触发执行机制）。 将事务执行过程中产生的日志时间（log event）写入缓冲区，每个事务线程都有一个缓冲区。Log Event保存在一个binlog_cache_mngr数据结构中，在该结构中有两个缓冲区，一个是stmt_cache，用于存放不支持事务的信息；另一个是trx_cache，用于存放支持事务的信息。 事务在提交阶段会将产生的log event写入到外部binlog文件中。不同事务以串行方式将log event写入Binlog文件中，所以一个事务包含的log event信息在binlog文件中是连续的，中间不会插入其他事务的log event。 Binlog文件操作Binlog状态查看1show variables like 'log_bin'; 开启Binlog功能，需要修改my.cnf或my.ini配置文件，在[mysqld]下面增加log_bin=mysql_bin_log，重启 MySQL服务。 12binlog-format=ROWlog-bin=mysqlbinlog 使用show binlog events命令1234show binary logs; //等价于show master logs;show master status;show binlog events;show binlog events in 'mysqlbinlog.000001'; 使用mysqlbinlog 命令12mysqlbinlog &quot;文件名&quot;mysqlbinlog &quot;文件名&quot; &gt; &quot;test.sql&quot; 使用 binlog 恢复数据12345//按指定时间恢复mysqlbinlog --start-datetime=&quot;2021-02-28 18:00:00&quot; --stopdatetime=&quot;2021-03-01 00:00:00&quot; mysqlbinlog.000001 | mysql -uroot -p123456//按事件位置号恢复mysqlbinlog --start-position=1789 --stop-position=2674 mysqlbinlog.000001| mysql -uroot -p123456 删除Binlog文件123purge binary logs to 'mysqlbinlog.000001'; //删除指定文件purge binary logs before '2021-03-01 00:00:00'; //删除指定时间之前的文件reset master; //清除所有文件 可以通过设置expire_logs_days参数来启动自动清理功能。默认值为0表示没启用。设置为大于0的整数表示超出多少天binlog文件会自动清除。","link":"/mysql/mysql%E6%97%A5%E5%BF%97%E7%B3%BB%E7%BB%9F.html"},{"title":"数据库中事务的几种隔离级别","text":"4种现象与4种隔离级别 关系型数据库在正常的使用过程中，也存在一些并发的场景。而一出现并发，就会出现各种各样的问题，例如：脏写、脏读、不可重复读、幻读，这都是些啥呢？下面一一具体举例解释。 脏写现象与读未提交(read uncommitted)隔离级别 事务 A 和事务 B 同时执行，它们都要对同一条数据进行修改(这条数据的值，假设为 data)。 首先是事务 A 将数据的值修改为 data1，暂时不提交事务； 然后事务 B 将数据的值修改为 data2，然后立马提交事务； 事务 A 可能由于自己的业务系统出现了异常，因此进行回滚操作，将数据的值重新回滚为 data。 在这个过程中，事务 A 一个回滚操作，将事务 B 修改的值也回滚了，一夜回到解放前，事务 B 白忙活一场，这种现象叫做脏写。它的本质就是一个事务将另一个事务提交的修改操作回滚了。 显然在数据库中，肯定不允许这种现象存在。那么该如何解决这种问题呢？加个写锁就能解决，要对数据修改，必须要先获取到这行数据的写锁，否则不能修改。 在事务 A 开启时，对 data 加上写锁，直到事务 A 提交事务以后，才释放锁，在此期间，其他事务由于获取不到锁，也就谈不上对 data 数据进行修改了。 在实际的数据库中，则是将事务的隔离级别设置为读未提交(read uncommitted) ，在该隔离级别下，能保证事务提交之前，其他事务不能同时对这条数据进行修改。 脏读现象与读提交(read committed)隔离级别 事务 A 和事务 B 同时执行，事务 A 先将数据从 data 修改为 data1，然后暂时不提交事务，而是继续向后处理业务逻辑。 然后事务 B 读取这一行数据，读取到值为 data1，然后基于 data1 这个值去处理自己的业务逻辑了。 接着事务 A 在处理后面的业务逻辑时出现了异常，因此要进行回滚操作，将数据从 data1 回滚为 data。 在这个过程中，当事务 B 再去查询时发现数据的值为 data，这就蛋疼了，本来是基于 data1 这个值去做的业务逻辑处理，结果现在发现值却是 data，完蛋了，全 NM 错了，这种现象就是脏读，它的本质就是一个事务读到了另一个事务未提交的值。 为了解决脏读的问题，数据库中定义了读提交(read committed) 隔离级别，它的意思就是，在读数据的时候，只能读到别的事务提交过后的值，对于未提交的事务对数据所做的修改操作，当前事务是无法读取到的。 在读提交的事务隔离级别下，当事务 B 去读取数据时，发现事务 A 还没有提交，因此它不能读取到 data1 这个值，只能读取到 data 这个值。 不可重复读现象与可重复读(repeatable read)隔离级别 假设现在数据库中事务的隔离级别为读提交，也就是未提交的事务修改的值，其他事务是读取不到的，那么在当前事务隔离级别下还会有其他问题吗？ 事务 A 和事务 B 同时开启事务，事务 A 先从数据库查询数据，读取到的值为 data，然后事务 A 先不提交事务。 接着事务 B 修改数据，将数据的值从 data 修改为 data1。 如果事务 B 先不提交事务，那么事务 A 此时来读取数据时，能读取到最新的值 data1 吗？不能，因为我们假设了此时事务的隔离级别处于读提交状态。 好，既然不能事务 A 不能读取到最新值，那么现在事务 B 提交事务，接着让事务 A 再次从数据库查询数据，此时能读取到最新的值吗？ 能，此时读取到的值为 data1，因为事务 B 已经提交了事务，在读提交的隔离级别下，提交了的事务，其他事务都能读取到最新的值。 但是这有问题啊！在同一个事务内（事务 A），它读取了两次数据，发现前后两次读取到的值分别是 data 和 data1，同一行数据，读到的值却不一样. 实际上这就是不可重复读现象，它的本质就是在同一个事务内，多次从数据库读取数据，读取到的值不一样。（注意不可重复读与脏读的区别：脏读是指读到了未提交事务的值，不可重复读指的是其他事务更新数据并提交后，自己前后读取到的数据不一致） 因此，可重复读(repeatable read) 事务隔离级别出现了，它的意思是，在同一个事务内，例如事务 A，多次从数据库读取数据时，每次读取到的值是一样的，即使在此期间有其他事务修改了这条数据的值，也不会导致事务 A 前后两次读取到的值不一样。 幻读现象与串行化(serializable)隔离级别假设事务 A 和事务 B 并发执行，首先事务 A 先执行了如下 SQL，假设查到了 1 条数据 12### 假设只查询出来一条数据select * from t where id &gt; 1 接着事务 B 向数据库中又新插入了 10 条数据，并提交了事务； 然后事务 A 又使用同样的 SQL 语句查询数据，这时会查询出来 11 条数据，比之前查出来的数据多，也就是说看到了更多的数据，这种现象就是幻读。 注意幻读与不可重复读的区别：幻读特指在同一个事务内，前后两次查询，后面的查询，读到了之前没看到的数据；而不可重复读指的是在同一个事务内，针对同一行数据而言，前后两次查询，读取到的值不一样。 为了解决幻读的问题，数据库提出了串行化(Serializable) 这种事务隔离级别。 那么什么是串行化呢？归根结底，出现脏写、脏读、不可重复读、幻读这些问题，都是因为并发导致的，那要一下子全部解决这些问题，最简单的办法就是不要让线程并发执行，让多个线程一个一个执行，也就是串行化（也就是不让并发出现，都没有并发了，也就没有脏写、脏读、不可重复读、幻读这些幺蛾子了）。 总结由于事务的并发执行，会造成很多异常的现象，例如脏写、脏读、不可重复读、幻读等。 这四种现象总结起来就是： 脏写指的是一个事务将其他事务提交的修改回滚了； 脏读指的是一个事务读取到了另一个事务未提交的修改值； 不可重复读指的是一个事务对同一条数据，两次前后读取到的值不一样，这是因为在此期间有其他事务更新了该条数据； 幻读指的是一个事务，后一次的查询比前一次查询看到的数据多了，它特指读到了新的数据，需要与不可重复读的现象区分开来。 为了解决这些问题，SQL 标准（注意：这里说的是 SQL 标准）中定义了 4 种事务的隔离级来应对这些现象，分别是:读未提交、读提交、可重复读、串行化，它们的强度也依次递增。在这四种隔离级别下，它们的表现如下： 脏写 脏读 不可重复读 幻读 读未提交 ❌ ✅ ✅ ✅ 读提交 ❌ ❌ ✅ ✅ 可重复读 ❌ ❌ ❌ ✅ 串行化 ❌ ❌ ❌ ❌ 实际上，这四种事务的隔离级别只是 SQL 标准中定义的，在各大数据库中，这 4 种隔离级别在实现细节上又有所不同，例如：对于 MySQL 的 InnoDB 存储引擎而言，在可重复读隔离级别下，MySQL 通过 MVCC 机制解决了幻读的问题（在 SQL 标准中，可重复读隔离级别下仍存在幻读的问题）。","link":"/mysql/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%AD%E4%BA%8B%E5%8A%A1%E7%9A%84%E5%87%A0%E7%A7%8D%E9%9A%94%E7%A6%BB%E7%BA%A7%E5%88%AB.html"},{"title":"undo log版本链与ReadView机制“","text":"undo log 版本链 在 MySQL 的数据表中，存储着一行行的数据记录，对每行数据而言，不仅仅记录着我们定义的字段值，还会隐藏两个字段：row_trx_id 和 roll_pointer，前者表示更新本行数据的事务 id，后者表示的是回滚指针，它指向的是该行数据上一个版本的 undo log 当我们进行数据的新增、删除、修改操作时，会写 redo log(解决数据库宕机重启丢失数据的问题)和 binlog(主要用来做复制、数据备份等操作)，另外还会写 undo log，它是为了实现事务的回滚操作。 每一条 undo log 的具体内容可以自行网上查阅。我们只需要知道每行 undo log 日志会记录对应的事务 id，还会记录当前事务将数据修改后的最新值，以及指向当前行数据上一个版本的 undo log 的指针，也就是 roll_pointer。 为了方便理解，每一行 undo log 可以简化为下图所示的结构 举个例子，现在有一个事务 A，它的事务 id 为 10，向表中新插入了一条数据，数据记为 data_A，那么此时对应的 undo log 应该如下图所示： 接着事务 B(trx_id=20)，将这行数据的值修改为 data_B，同样也会记录一条 undo log，如下图所示，这条 undo log 的 roll_pointer 指针会指向上一个数据版本的 undo log，也就是指向事务 A 写入的那一行 undo log。 再接着，事务 C(trx_id=30)，将这行数据的值修改为 data_C，对应的示意图如下。 只要有事务修改了这一行的数据，那么就会记录一条对应的 undo log，一条 undo log 对应这行数据的一个版本，当这行数据有多个版本时，就会有多条 undo log 日志，undo log 之间通过 roll_pointer 指针连接，这样就形成了一个 undo log 版本链 ReadView机制当事务在开始执行的时候，会给每个事务生成一个 ReadView。这个 ReadView 会记录 4 个非常重要的属性 creator_trx_id: 当前事务的 id； m_ids: 当前系统中所有的活跃事务的 id，活跃事务指的是当前系统中开启了事务，但是还没有提交的事务； min_trx_id: 当前系统中，所有活跃事务中事务 id 最小的那个事务，也就是 m_id 数组中最小的事务 id； max_trx_id: 当前系统中事务的 id 值最大的那个事务 id 值再加 1，也就是系统中下一个要生成的事务 id。 ReadView 会根据这 4 个属性，再结合 undo log 版本链，来实现 MVCC 机制，决定让一个事务能读取到哪些数据，不能读取到哪些数据。 当一个事务读取某条数据时，就会按照如下规则来决定当前事务能读取到什么数据： 如果当前数据的 row_trx_id 小于 min_trx_id，那么表示这条数据是在当前事务开启之前，其他的事务就已经将该条数据修改了并提交了事务(事务的 id 值是递增的)，所以当前事务能读取到。 如果当前数据的 row_trx_id 大于等于 max_trx_id，那么表示在当前事务开启以后，过了一段时间，系统中有新的事务开启了，并且新的事务修改了这行数据的值并提交了事务，所以当前事务肯定是不能读取到的，因此这是后面的事务修改提交的数据。 如果当前数据的 row_trx_id 处于 min_trx_id 和 max_trx_id 的范围之间，又需要分两种情况： （a）row_trx_id 在 m_ids 数组中，那么当前事务不能读取到。为什么呢？row_trx_id 在 m_ids 数组中表示的是和当前事务在同一时刻开启的事务，修改了数据的值，并提交了事务，所以不能让当前事务读取到； （b) row_trx_id 不在 m_ids 数组中，那么当前事务能读取到。row_trx_id 不在 m_ids 数组中表示的是在当前事务开启之前，其他事务将数据修改后就已经提交了事务，所以当前事务能读取到。 注意：如果 row_trx_id 等于当前事务的 id，那表示这条数据就是当前事务修改的，那当前事务肯定能读取到啊。 先假设表中有一条数据，它的 row_trx_id=10，roll_pointer 为 null，那么此时 undo log 版本链就是下图这样： 假设现在有事务 A 和事务 B 并发执行，事务 A 的事务 id 为 20，事务 B 的事务 id 为 30。 那么此时对于事务 A 而言，它的 ReadView 中，m_ids=[20,30]，min_trx_id=20，max_trx_id=31，creator_trx_id=20。 对于事务 B 而言，它的 ReadView 中，m_ids=[20,30]，min_trx_id=20，max_trx_id=31，creator_trx_id=30。 如果此时事务 A(trx_id=20)去读取数据，那么在 undo log 版本链中，数据最新版本的事务 id 为 10，这个值小于事务 A 的 ReadView 里 min_trx_id 的值，这表示这个数据的版本是事务 A 开启之前，其他事务提交的，因此事务 A 可以读取到，所以读取到的值是 data0。 接着事务 B(trx_id=30)去修改数据，将数据修改为 data_B，先不提交事务。虽然不提交事务，但是仍然会记录一条 undo log，因此这条数据的 undo log 的版本链就有两条记录了，新的这条 undo log 的 roll_pointer 指针会指向前一条 undo log，示意图如下。 接着事务 A(trx_id=20)去读取数据，那么在 undo log 版本链中，数据最新版本的事务 id 为 30，这个值处于事务 A 的 ReadView 里 min_trx_id 和 max_trx_id 之间，因此还需要判断这个数据版本的值是否在 m_ids 数组中，结果发现，30 确实在 m_ids 数组中，这表示这个版本的数据是和自己同一时刻启动的事务修改的，因此这个版本的数据，数据 A 读取不到。所以需要沿着 undo log 的版本链向前找，接着会找到该行数据的上一个版本，也就是 trx_id=10 的版本，由于这个版本的数据的 trx_id=10，小于 min_trx_id 的值，因此事务 A 能读取到该版本的值，即事务 A 读取到的值是 data0。 紧接着事务 B 提交事务，那么此时系统中活跃的事务就只有 id 为 20 的事务了，也就是事务 A。那么此时事务 A 再去读取数据，它能读取到什么值呢？还是 data0。为什么呢？ 虽然系统中当前只剩下 id 为 20 的活跃事务了，但是事务 A 开启的瞬间，它已经生成了 ReadView ，后面即使有其他事务提交了，但是事务 A 的 ReadView 不会修改，也就是 m_ids 不会变，还是 m_ids=[20,30]，所以此时事务 A 去根据 undo log 版本链去读取数据时，还是不能读取最新版本的数据，只能往前找，最终还是只能读取到 data0。 接着系统中，新开了一个事务 C，事务 id 为 40，它的 ReadView 中，m_ids=[20,40]，min_trx_id=20，max_trx_id=41，creator_trx_id=40。 然后事务 C(trx_id=40)将数据修改为 data_C，并提交事务。此时 undo log 版本链就变成了如下图所示 此时事务 A(trx_id=20)去读取数据，那么在 undo log 版本链中，数据最新版本的事务 id 为 40，由于此时事务 A 的 ReadView 中的 max_trx_id=31，40 大于 31，这表示当前版本的数据时在事务 A 之后提交的，因此对于事务 A 肯定是不能读取到的。所以此时事务 A 只能根据 roll_pointer 指针，沿着 undo log 版本向前找，结果发现上一个版本的 trx_id=30，自己还是不能读取到，所以再继续往前找，最终可以读取到 trx_id=10 的版本数据，因此最终事务 A 只能读取到 data0。 接着事务 A(trx_id=20)去修改数据，将数据修改为 data_A，那么就会记录一条 undo log，示意图如下： 然后事务 A(trx_id=20)再去读取数据，在 undo log 版本链中，数据最新版本的事务 id 为 20，事务 A 一对比，发现该版本的事务 id 与自己的事务 id 相等，这表示这个版本的数据就是自己修改的，既然是自己修改的，那就肯定能读取到了，因此此时读取到是 data_A。 如何通过MVCC来解决不可重复读和幻读不可重复度 参照上面ReadView的机制讲解的例子，这里补充一下 事务 A 的 ReadView 是在发起第一次查询的时候创建的，当时系统中的活跃事务有 20 和 30 这两个 id，那么此时当事务 B 提交以后，事务 A 的 ReadView 的 m_ids 会变化吗？不会。因为是可重复读隔离级别下，对于读事务，只会在事务查询的第一次创建 ReadView，后面的查询不会再重新创建 幻读 幻读特指后面的查询比前面的查询的记录条数多，看到了前面没看到的数据，就像产生幻觉一样，因此称之为幻读。 (补)快照读与当前读 在解释 MySQL 的可重复读隔离级别解决了幻读问题之前，我们先来看两个定义：「快照读与当前读」。 我们知道，在事务开启的时候，会基于当前系统中数据库的数据，为每个事务生成一个快照，也叫做 ReadView，后面这个事务所有的读操作都是基于这个 ReadView 来读取数据，这种读称之为快照读。「我们在实际的工作中，所使用的 SQL 查询语句基本都是快照读。」 通过前面介绍的 undo log 版本链，我们知道，每行数据可能会有多个版本，如果每次读取时，「我们都强制性的读取最新版本的数据，这种读称之为当前读，也就是读取最新的数据」。什么样的 SQL 查询语句叫做当前读呢？例如在 select 语句后面加上「for update 或者 lock in share mode」等 1234# 加上排他锁select * from t for update;# 加上共享锁select * from t for lock in share mode; 可以发现，当前读的这两种写法，在查询过程中都是需要加锁的，因此它们能读取到最新的数据。 在 MySQL 可重复读隔离级别下，幻读问题确实不存在。但是 MVCC 机制解决的是快照读的幻读问题，并不能解决当前读的幻读问题。当前读的幻读问题是通过间隙锁解决的 以下是基于快照读来进行解读 假设现在表 t 中只有一条数据，数据内容中，主键 id=1，隐藏的 trx_id=10，它的 undo log 如下图所示 假设现在有事务 A 和事务 B 并发执行，事务 A 的事务 id 为 20，事务 B 的事务 id 为 30。 现在事务 A 开始第一次查询数据，查询的 SQL 语句如下。 1select * from where id &gt;= 1; 在开始查询之前，MySQL 会为事务 A 产生一个 ReadView，此时 ReadView 的内容如下：m_ids=[20,30]，min_trx_id=20，max_trx_id=31，creator_trx_id=20。 由于此时表 t 中只有一条数据，且符合 where id&gt;=1 条件，因此会查询出来。然后通过 ReadView 机制，发现该行数据的 row_id=10，小于事务 A 的 ReadView 里 min_trx_id，这表示这条数据是事务 A 开启之前，其他事务就已经提交了的数据，因此事务 A 可以读取到。 接着事务 B(trx_id=30)，往表 t 中新插入两条数据，SQL 语句如下。 12insert into t(id,name) values(2,'小明');insert into t(id,name) values(3,'小红'); 然后事务提交事务，那么此时表 t 中就有三条数据了，对应的 undo 如下图所示： 接着事务 A 开启第二次查询，根据可重复读隔离级别的规则，此时事务 A 并不会再重新生成 ReadView。此时表 t 中的 3 条数据都满足 where id&gt;=1 的条件，因此会先查出来，然后再根据 ReadView 机制，判断每条数据是不是都可以被事务 A 看到。 首先 id=1 的这条数据，前面已经说过了，可以被事务 A 看到。 然后是 id=2 的数据，它的 trx_id=30，此时事务 A 发现，这个值处于 min_trx_id 和 max_trx_id 之间，因此还需要再判断 30 是否处于 m_ids 数组内。由于事务 A 的 m_ids=[20,30]，因此在数组内，这表示 id=2 的这条数据是与事务 A 在同一时刻启动的其他事务提交的，所以这条数据不能让事务 A 看到。 同理，id=3 的这条数据，trx_id 也为 30，因此也不能被事务 A 看见。 结论：最终事务 A 的第二次查询，只能查询出 id=1 的这条数据。这和事务 A 的第一次查询的结果是一样的，因此没有出现幻读现象，所以说在 MySQL 的可重复读隔离级别下，不存在幻读问题。","link":"/mysql/undo-log%E7%89%88%E6%9C%AC%E9%93%BE%E4%B8%8EReadView%E6%9C%BA%E5%88%B6%E2%80%9C.html"}],"tags":[{"name":"mysql","slug":"mysql","link":"/tags/mysql/"},{"name":"Netty","slug":"Netty","link":"/tags/Netty/"},{"name":"JVM","slug":"JVM","link":"/tags/JVM/"},{"name":"八股文","slug":"八股文","link":"/tags/%E5%85%AB%E8%82%A1%E6%96%87/"},{"name":"JAVA","slug":"JAVA","link":"/tags/JAVA/"}],"categories":[{"name":"Netty","slug":"Netty","link":"/categories/Netty/"},{"name":"Netty源码剖析","slug":"Netty/Netty源码剖析","link":"/categories/Netty/Netty%E6%BA%90%E7%A0%81%E5%89%96%E6%9E%90/"},{"name":"八股文","slug":"八股文","link":"/categories/%E5%85%AB%E8%82%A1%E6%96%87/"},{"name":"JVM","slug":"八股文/JVM","link":"/categories/%E5%85%AB%E8%82%A1%E6%96%87/JVM/"},{"name":"mysql","slug":"mysql","link":"/categories/mysql/"}]}